{"posts":[{"title":"Vitis HLS 实现手写数字识别","content":"Vitis HLS (原 Vivado HLS ) 是一个高级综合工具，用户可以通过该工具直接将 C/C++ 编写的函数翻译成 HDL 硬件描述语言，最终再映射成 FPGA 内部的LUT、DSP 资源以及 RAM 资源等。用户通过 Vitis HLS，使用 C/C++ 代码来开发 RTL IP 核，可以缩短整个 FPGA 项目的开发和验证时间。 1 网络模型 LeNet 是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。这个模型是由 AT&amp;T 贝尔实验室的研究员 Yann LeCun 在1989年提出的，目的是识别图像中的手写数字。总体来看，LeNet (LeNet-5) 由两个部分组成，如下图所示： 卷积编码器：由两个卷积块组成，每个卷积块中的基本单元是一个卷积层、一个 sigmoid 激活函数和平均汇聚层 全连接层密集块：由三个全连接层组成 本文使用王小雪[1]论文中的网络模型，该模型共有五层，分别为卷积层 C1、降采样层 S1、卷积层 C2、降采样层 S2 和全连接层 D1。在卷积层 C1 中完成的是 28×2828 \\times 2828×28 的初始输入图像与 5×55 \\times 55×5 的卷积核之间的卷积计算。在卷积层 C2 中完成的是 12×1212 \\times 1212×12 的特征图与 5×55 \\times 55×5 的卷积核之间的卷积计算。 2 模型训练和参数提取 使用 TensorFlow 搭建网络模型，考虑到后续会使用低精度定点数存储模型参数，将后端默认的浮点类型设置为 16 位。 import tensorflow as tf def LeNet(): return tf.keras.models.Sequential([ tf.keras.layers.Conv2D(filters=3, kernel_size=5, activation='sigmoid'), tf.keras.layers.AvgPool2D(pool_size=2, strides=2), tf.keras.layers.Conv2D(filters=12, kernel_size=5, activation='sigmoid'), tf.keras.layers.AvgPool2D(pool_size=2, strides=2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(10)]) tf.keras.backend.set_floatx('float16') 模型训练使用的数据集为 MNIST，训练集和测试集的处理如下： mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() batch_size = 256 process = lambda X, y: (tf.expand_dims(X, axis=3) / 255, tf.cast(y, dtype=&quot;int32&quot;)) resize_fn = lambda X, y: (tf.image.resize_with_pad(X, None, None) if None else X, y) train_iter = ( tf.data.Dataset.from_tensor_slices(process(*mnist_train)) .batch(256) .shuffle(len(mnist_train[0])) .map(resize_fn) ) test_iter = ( tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(256).map(resize_fn) ) 模型训练的代码如下，将表现最好的模型保存在 ./weights/best_model.h5 中。 from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint # model fitting if len(tf.config.experimental.list_physical_devices('GPU')) &gt;= 1: device = tf.device(f'/GPU:{0}') else: device = tf.device('/CPU:0') device_name = device._device_name strategy = tf.distribute.OneDeviceStrategy(device_name) lr = 0.9 num_epochs = 40 with strategy.scope(): optimizer = tf.keras.optimizers.SGD(learning_rate=lr) loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) net = LeNet() net.compile(optimizer=optimizer, loss=loss, metrics=[&quot;accuracy&quot;]) earlystop_callback = EarlyStopping(monitor=&quot;accuracy&quot;, min_delta=0.0001, patience=5) reduce_lr_callback = ReduceLROnPlateau(monitor=&quot;accuracy&quot;, factor=0.5, patience=3) checkpoint_callback = ModelCheckpoint( &quot;./weights/best_model.h5&quot;, monitor=&quot;accuracy&quot;, save_best_only=True ) net.fit( train_iter, epochs=num_epochs, verbose=1, callbacks=[earlystop_callback, reduce_lr_callback, checkpoint_callback], ) 以上代码参考了《动手学深度学习》第二版[2] 6.6 节卷积神经网络 (LeNet) 中的内容。模型训练的进展详情如下图所示。 模型训练完成后，通过 net.layers[i].get_weights() 能够访问各层的参数。先查看各层参数的 shape，可以发现其中只有两层卷积层 Conv2D 和一层全连接层 Dense 需要保存参数。 X = tf.random.uniform((1, 28, 28, 1)) for layer in net.layers: X = layer(X) print(layer.__class__.__name__, X.shape) for item in layer.weights: print(' ', item.name, ' \\tshape: ', item.shape) ''' Conv2D (1, 24, 24, 3) conv2d/kernel:0 shape: (5, 5, 1, 3) conv2d/bias:0 shape: (3,) AveragePooling2D (1, 12, 12, 3) Conv2D (1, 8, 8, 12) conv2d_1/kernel:0 shape: (5, 5, 3, 12) conv2d_1/bias:0 shape: (12,) AveragePooling2D (1, 4, 4, 12) Flatten (1, 192) Dense (1, 10) dense/kernel:0 shape: (192, 10) dense/bias:0 shape: (10,) ''' 将参数保存在 txt 文件中，虽然保存为二进制文件更加节省资源，但文本文件方便观察和调试。参数保存的精度为四位小数。 # path to your Vitis HLS testbehch folder path = 'xxx' # generate weight and bias files file = open(path+'LeNet_weights.txt', 'w') bias_arr = net.layers[0].get_weights()[1] arr = net.layers[0].get_weights()[0].reshape(-1) for i in range(25*3): file.write('%.4f ' % arr[i]) file.write('\\n') for i in range(3): file.write('%.4f ' % bias_arr[i]) file.write('\\n') bias_arr = net.layers[2].get_weights()[1] arr = net.layers[2].get_weights()[0].reshape(-1) for i in range(25*12*3): file.write('%.4f ' % arr[i]) file.write('\\n') for i in range(12): file.write('%.4f ' % bias_arr[i]) file.write('\\n') arr = net.layers[5].get_weights()[0].reshape(-1) for i in range(1920): file.write('%.4f ' % arr[i]) file.write('\\n') arr = net.layers[5].get_weights()[1].reshape(-1) for i in range(10): file.write('%.4f ' % arr[i]) file.close() 3 HLS 代码 该节部分代码的优化参考了一篇 CSDN 博客[3]，详见 VitisHLS_LeNet。 4 仿真和综合结果 为每一层的函数编写对应的 testbench 测试文件，比较相同输入数据下 HLS C 仿真的结果与 Python 运算的结果是否在误差允许的范围内。误差门限 ERROR_GAP 为 0.010.010.01，每超过一次门限便统计一次，当单个测试用例有 10 次超过门限就判定为失败。 if (hls::absf(expected_output_arr[i][k][r][c] - output_arr[k][r][c]) &gt; ERROR_GAP) mismatch_count++ 使用 MNIST 测试集前 100 例数据用于各层的功能测试，用前 1000 例数据测试整个系统的识别正确率。C Simulation 的结果如下，可以看到各个模块的测试均无异常，系统的识别正确率为 98.098.0%98.0。 C Synthesis 的部分结果如下，整个模块的延迟为 308μs308 \\mu \\text{s}308μs，无 Timing Violation 和 II Violation。 5 参考文献 [1]王小雪. 基于FPGA的卷积神经网络手写数字识别系统的实现[D].北京理工大学,2016. [2]Zhang A, Lipton Z C, Li M, et al. Dive into deep learning[J]. arXiv preprint arXiv:2106.11342, 2021. [3]HLS学习笔记——实现卷积层的加速计算 ","link":"https://SylvanasQAQ.github.io/post/bt9ZR2x4y/"},{"title":"Verilog 语法","content":"本文大部分内容来自《数字设计和计算机体系结构》第二版第 4 章——硬件描述语言。 1 引言 在更高的抽象层描述数字电路的逻辑功能，使用计算机辅助设计 (Computer-Aided Design, CAD) 工具来生成优化的门电路，可以获得更高的设计效率。对硬件的描述通常由硬件描述语言 (Hardware Description Language, HDL) 给出，现在有两种主要的硬件描述语言，它们分别是 SystemVerilog 和 VHDL。 VHDL 比 SystemVerilog 的语句冗长且不灵活，工业界倾向于使用 SystemVerilog。但两种语言都足以描述任何的硬件系统，也都各自有自己的特点。一门最好的语言就是在你的环境里已经使用的语言或者是客户要求使用的语言。SystemVerilog 和 VHDL 的基本原理很相似，但二者的语法却有所不同，本文将简要介绍 SystemVerilog 的语法。 Verilog 于 1990 年成为一个公开的标准，1995 年成为 IEEE 标准。Verilog 语言于 2005 年进行扩展使其特征简化，并更好地支持模块化设计与系统验证。这些扩展融入一个语言标准中，这就是 SystemVerilog (IEEE STD 1800-2009)。SystemVerilog 文件名通常以 .sv 结束。 1.1 模块 包括输入和输出的硬件块称为模块 (module)，它定义了由输入和输出组成的接口，并且执行特定的功能。其编码内容对于调用该模块的其他模块并不重要，只要它执行自己的功能。描述模块功能的主要形式有两种： 行为模型 (behavioral)：描述一个模块做什么 结构模型 (structural)：应用层次化方法描述一个模块怎样由更简单的部件构造 一个 SystemVerilog 模块以模块名、以及输入和输出列表开始。assign 语句描述组合逻辑，~ 表示非，&amp; 表示与，| 表示或。logic 变量类型可以用于任何地方，除了具有多个驱动的信号外（具有多个驱动器的信号称为 net）。 module sillyfunction ( input logic a,b,c output logic y ); assign y = ~a &amp; ~b &amp; ~c | a &amp; ~b &amp; ~c | a &amp; ~b &amp; c; endmodule 1.2 模拟和综合 两种硬件描述语言的主要目的是逻辑模拟 (simulation) 和综合 (synthesis)。 模拟阶段，给模块增加输入，并检查输出以便验证模块操作是否正确 综合阶段，将模块的文字描述转换成逻辑门 模拟 硬件设计里的错误被称为漏洞 (bug)，去除数字系统中的漏洞十分重要。在系统完成后才改正错误付出的代价极度昂贵，Intel 曾经因为奔腾处理器的浮点除法漏洞花费了 4.75 亿美元，所以在系统建立前进行逻辑模拟是很必要的。下图是前面 sillyfunction 模块的模拟波形 综合 逻辑综合将 HDL 代码转换成网表 (netlist)，网表描述硬件，比如逻辑门和连线。逻辑综合可以进行优化以便减少硬件的数量，比如下图中显示了由 3 个 3 输入与门简化为 2 个 2 输入与门的结果。 HDL 代码可以分成可综合 (synthesizable) 模块和测试程序 (testbench)。可综合模块描述硬件，测试程序包含将输入应用于模块的代码，检测输出结果是否正确，并输出期望结果与实际结果的差别。测试程序代码只用于模拟，不能用于综合。 HDL 有一些特定的方法来描述各种的逻辑，这些方法称为风格 (idiom)。本文将讲述如何针对每一类模块采用合适的风格编写 HDL 代码，然后如何把各块聚集起来成为一个可以工作的系统。 2 组合逻辑 组合逻辑的输出只依赖当前输入，本节描述如何用 SystemVerilog 编写组合逻辑的行为模型。 2.1 位运算符 位 (bitwise) 运算符对单位信号和多位总线进行操作，下面的 inv 模块描述 4 个连接到 4 位总线的反向器。其中 a[3:0] 代表一个 4 位的总线，这些位从最高有效位到最低有效位分别是 a[3], a[2], a[1], a[0]。因为这里最低有效位的位号最小，所以称为小端 (little-endian) 顺序。 module inv( input logic [3:0] a, output logic [3:0] y ); assign y = ~a; endmodule 总线的字节顺序 (endianness) 是任意选择的。只要保持一致，可以采用任意一种字节顺序。 2.2 注释和空白 SystemVerilog 对空白并不敏感，包括空格、Tab 键和换行，但合理使用缩进排版和换行可以增加复杂设计的可读性。SystemVerilog 是大小写敏感的，但只通过大小写来区分不同的信号容易造成混乱。 SystemVerilog 的注释与 C 的一样，有两种： 多行注释：以 /* 开始，之后的内容可以延续多行，以下一个 */ 结束 单行注释：以 // 开始的注释则一直延续到本行的末尾 下面的代码中展示了一些基本的概念，其中 ~、^ 和 | 都是 Verilog 运算符 (operator)，a、b 和 y1 是运算数 (operand)。运算符和运算数的组合，如 a&amp;b，称为表达式 (expression)。一条完整的命令，如 assign y4 = ~(a&amp;b); 称为语句 (statement)。 module gates( input logic [3:0] a, b, output logic [3:0] y1, y2, y3, y4, y5 ); /* five different tow-input logic gates acting on 4-bit busses */ assign y1 = a &amp; b; // AND assign y2 = a | b; // OR assign y3 = a ^ b; // XOR assign y4 = ~(a&amp;b); // NAND assign y5 = ~(a|b); // NOR endmodule assign out = in1 op in2; 称为连续赋值语句 (continuous assignment statement)，连续赋值语句以一个分号结束。在连续赋值语句中，等号右边的输入值改变，等号左边的输出就会随之重新计算。因此，连续赋值语句描述组合逻辑。 2.3 缩位运算符 缩位运算符表示作用在一条总线上的多输入门。下面的代码描述了一个 8 输入与门，或门、异或门和与非门等也有类似的缩位运算符。 module and8 ( input logic [7:0] a, output logic y ); // same as assign y = a[7] &amp; a[6] &amp; a[5] &amp; a[4] &amp; // a[3] &amp; a[2] &amp; a[1] &amp; a[0]; assign y = &amp;a; endmodule 2.4 条件赋值 条件赋值 (conditional assignment) 根据称为条件的输入在所有可选项中选择一个输出。下面的代码说明了一个使用条件赋值的 2:1 复用器。条件运算符 ?: 基于第一个表达式，在第二个表达式和第三个表达式之间选择。?: 对于描述复用器特别有用。 module mux2 ( input logic [3:0] d0, d1, input logic s, output logic [3:0] y ); assign y = s ? d1 : d0; endmodule 2.5 内部变量 通常，把一个复杂功能分为几个中间过程来完成会更方便。全加器是一个有 3 个输入和 2 个输出的电路，它由以下等式定义： S=A⊕B⊕Cin Cout =AB+ACin +BCin \\begin{aligned} S &amp;=A \\oplus B \\oplus C_{\\text {in }} \\\\ C_{\\text {out }} &amp;=A B+A C_{\\text {in }}+B C_{\\text {in }} \\end{aligned} SCout ​​=A⊕B⊕Cin ​=AB+ACin ​+BCin ​​ 如果我们定义中间信号 PPP 和 GGG， P=A⊕BG=AB\\begin{array}{l} P=A \\oplus B \\\\ G=A B \\end{array} P=A⊕BG=AB​ 则可以重写全加器： S=P⊕Cin Cout =G+PCin \\begin{array}{l} S=P \\oplus C_{\\text {in }} \\\\ C_{\\text {out }}=G+P C_{\\text {in }} \\end{array} S=P⊕Cin ​Cout ​=G+PCin ​​ PPP 和 GGG 称为内部变量 (internal variable)，它们既不是输入也不是输出，只在模块内部使用。Verilog 赋值语句 assign 是并行执行的，在 HDL 中这些并行语句的顺序并不重要。 module fulladder ( input logic a, b, cin, output logic s, cout ); logic p, g; assign p = a ^ b; assign g = a &amp; b; assign s = p ^ cin; assign cout = g | (p &amp; cin); endmodule 2.6 优先级 上面的代码中为 cout 的计算添加了括号，以便把运算顺序定义为 Cout=G+(P⋅Cin)C_{\\text{out}} = G + (P \\cdot C_{\\text{in}})Cout​=G+(P⋅Cin​)。如果没有使用括号，就采用语言定义的默认运算顺序。下图是 Verilog 运算符的优先级。 2.7 数字 数字可以采用二进制、八进制、十进制或者十六进制来表示。可以指定数字的位数，数字中间出现的下划线会被忽略，但是可以增强可读性。SystemVerilog 声明常量的格式是 N'Bvalue，其中 NNN 是位数，BBB 是说明基数的字母，value 是值。'b 表示二进制，'o 表示八进制，'d 表示十进制，'h 表示十六进制。 如果没有提供基数，那么基数默认为 10。如果没有给出位数，那么数字就赋予当前表达式的位数，0 会自动填补在数字的前面以达到满位。比如 w 是 6 位总线，assign w = 'b11 会给 w 赋予 000011。明确地说明位数大小是比较好的。但是有个例外，'0 和 '1 分别是将全 0 和全 1 赋值给一条总线的 SystemVerilog 惯用语法。 2.8 Z 和 X SystemVerilog 用 z 表示浮空值，对于描述三态缓存器尤其有用——当使能位为 0 时，它的输出为浮空。总线可以由多个三态缓存器驱动，但其中最多只有一个使能。如果缓存器被使能，输入和输出一致；如果缓存器被禁用，输出就为浮空值 (z)。 下面的代码展示了一个三态缓存器的风格。其中 y 声明为 tri 变量类型而不是 logic 变量类型。logic 信号只能有一个信号源驱动信号。三态总线可以有多个驱动信号，所以三态总线应声明为 net 变量。SystemVerilog 中 net 变量有 tri 和 trireg 两种类型。一般来说，每次只有一个驱动信号源处于激活状态，net 采纳该信号源的数值作为其信号数值。如果没有一个驱动信号源处于激活状态，则 tri 类型信号将处于悬空状态 (z)，而 trireg 类型信号则保持先前的数值。如果输入或输出变量没有指定变量类型，则默认为 tri 类型。 module tristate ( input logic [3:0] a, input logic en, output tri [3:0] y ); assign y = en ? a : 4'bz; endmodule SystemVerilog 使用 x 表示一个无效的逻辑电平。如果一条总线被两个使能的三态缓冲器同时驱动为 0 和 1，则结果是 X，说明发生了冲突。在模拟开始时，状态结点（如触发器输出）被初始化一个未知状态，这有助于追踪在使用输出前忘记复位触发器而引起的错误。如果一个门接收一个浮空输入，当它不能确定正确的输出值时，它将产生一个输出 x。如果它接收一个无效的或者未初始化的输入，它也会输出一个 x。 在模拟时看到的 x 或 z 值，基本已经说明出现了漏洞或不正确的编码。 2.9 位混合 常常需要在总线的子集上操作，或者连接信号来构成总线。这些操作称为位混合 (bit swizzling)。下面的例子中使用 {} 操作符连接总线，用位混合操作给 y 赋予 9 位值 c2c1d0d0d0c0101c_{2} c_{1} d_{0} d_{0} d_{0} c_{0} 101c2​c1​d0​d0​d0​c0​101。 其中 {3{d[0]}} 表示 d[0] 的 3 个拷贝。 assign y = {c[2:1], {3{d[0]}}, c[0], 3'b101}; 2.10 延迟 HDL 的语句可以与任意单位的延迟相关联，这对于在模拟预测电路工作速度和调试需要知道原因和后果时很有用。在综合时这些延迟被忽略，综合器产生的门延迟是由 tpdt_{\\text{pd}}tpd​ 和 tcdt_{\\text{cd}}tcd​ 决定的，而不是 HDL 代码中的数字。 `timescale 1ns/1ps module example ( input logic a, b, c, output logic y ); logic ab, bb, cb, n1, n2, n3; assign #1 {ab, bb, cb} = ~{a, b, c}; assign #2 n1 = ab &amp; bb &amp; cb; assign #2 n2 = a &amp; bb &amp; cb; assign #2 n3 = a &amp; bb &amp; c; assign #4 y = n1 | n2 | n3; endmodule SystemVerilog 文件可以包括说明每一个时间单位值的时间尺度指令，格式为 `timescale unit/precision，该语句表明每个时间单位为 1ns，模拟精度为 1ps。如果文件中没有给出时间尺度指令，将使用默认的单位和精度（一般两者都是 1ns）。在 SystemVerilog 中，# 符号用于说明延迟单位的数量，它可以放在 assign 语句中。 3 结构化建模 上一节讨论行为建模，它通过对输入和输出之间关系建立模型。本节介绍结构建模，它描述一个模块怎样由更简单的模块组成。 下面的例子说明怎样将 3 个 2:1 复用器组合成一个 4:1 复用器。2:1 复用器的每个拷贝称为一个实例 (instance)，同一个模块的多个实例由不同的名字区分。 module mux4 ( input logic [3:0] d0, d1, d2, d3, input logic [1:0] s, output logic [3:0] y ); logic [3:0] low, high; mux2 lowmux(d0, d1, s[0], low); mux2 highmux(d2, d3, s[0], high); mux2 finalmux(low, high, s[1], y); endmodule 一般来说，复杂系统都是分层定义的。通过实例化主要的组件的方式来结构化地描述整个系统。每一个组件由更小的模块结构化地构成，然后进一步分解直到组件足够简单可以描述行为。避免在一个单独模块中混合使用结构和行为描述是一种好的程序设计风格。 4 时序逻辑 HDL 综合器可以识别某种风格，然后把它们转换成特定的时序电路。其他的编码风格可以正确地模拟，但把出现明显或不明显的错误综合到电路中。本节介绍寄存器和锁存器的正确描述风格。 4.1 寄存器 大多数现代的商业系统都由寄存器构成，这些寄存器使用正边沿触发的 D 触发器。下面的例子给出了这种触发器的风格。在 SystemVerilog 的 always 语句中，信号保持它们原来的值直到敏感信号列表中的一个事件发生，该事件明显地引起它们改变。因此，具有合适敏感信号列表的代码，可以用于描述有记忆能力的时序电路。例如，触发器在敏感信号列表中只有 clk，说明在下一个 clk 的上升沿到来前 q 都保持原来的值。 module flop ( input logic clk, input logic [3:0] d, output logic [3:0] q ); always_ff @(posedge clk) q &lt;= d; endmodule 一般来说，SystemVerilog 的 always 语句写成如下的形式： always @(sensitivity list) statement; 只有当敏感信号列表 (sensitivity list) 中说明的事件发生时才执行 statement。在上面的例子中，语句是 q &lt;= d，读作 “q 得到 d”。&lt;= 称为非阻塞赋值，在后续 5.4 节中会详细介绍，目前可以看作一个普通的等号。在 always 语句中，&lt;= 代替了 assign。 always 语句可以用来表示触发器、锁存器或组合逻辑，取决于敏感信号列表和执行语句。正因为这样的灵活性，所以容易在不经意间制造出错误的硬件电路。SystemVerilog 引入 always_ff、always_latch 和 always_comb 来降低产生这些常见错误的风险。always_ff 的行为与 always 一样，但只用来表示触发器，如果用于表示其他器件时允许工具生成警告信息⚠️。 4.2 复位寄存器 当模拟开始或电路首次通电时，触发器或寄存器的输出是未知的，SystemVerilog 使用 x 来表示。一般来说，应该使用复位寄存器，这样在上电时可以把系统置于已知状态。复位可以是同步的也可以是异步的，异步复位马上就生效，而同步复位只能在时钟的下一个上沿时才能清除输出。 下面的例子说明了同步复位和异步复位触发器的风格。在 always 语句敏感信号列表中的多个信号用逗号或者 or 分隔。posedge reset 在异步复位触发器的敏感信号列表中，但不在同步复位触发器中。因此，异步复位触发器会马上响应 reset 的上升沿，但同步复位触发器只在时钟的上沿时响应 reset。 module flopr ( input logic clk, input logic reset, input logic [3:0] d, output logic [3:0] q ); // asynchronous reset always_ff @(posedge clk, posedge reset) if (reset) q &lt;= 4'b0; else q &lt;= d; endmodule module flopr ( input logic clk, input logic reset, input logic [3:0] d, output logic [3:0] q ); // synchronous reset always_ff @(posedge clk) if (reset) q &lt;= 4'b0; else q &lt;= d; endmodule 4.3 多寄存器 一条单独的 always 语句可以用于描述多个硬件，比如由两个背靠背连接的触发器组成的同步器。下面的例子描述了同步器，在 clk 的上升沿，d 复制到 n1，同时 n1 复制到 q。其中 begin/end 结构是必要的，因为有多条声明语句出现在 always 语句中，这与 C 语言中的 { }相似。 module sync ( input logic clk, input logic d, output logic q ); logic n1; always_ff @(posedge clk) begin n1 &lt;= d; // nonblocking q &lt;= n1; // nonblocking end endmodule 4.4 锁存器 当时钟为 HIGH 时，D 锁存器是透明的，允许数据从输入流向输出。当时钟为 LOW 时锁存器变为不透明的，保持原来的状态。不是所有的综合工具都能很好地支持锁存器，最好不使用锁存器而使用边沿触发器。 下面的例子展示了 D 锁存器的风格。always_latch 等同于 always@ (clk, d)，它是 SystemVerilog 中用来描述锁存器的首选风格。如果 clk 为 HIGH，则 d 的值传递给 q。否则 q 保持它原来的值。 module latch ( input logic clk, input logic [3:0] d, output logic [3:0] q ); always_latch if (clk) q &lt;= d; endmodule 5 更多组合逻辑 第二节使用赋值语句从行为上描述组合逻辑，第四节使用 always 语句描述时序电路。然而，always 语句也可以用于描述组合逻辑的行为，如果敏感信号列表包含对所有输入的响应，正文描述每一种可能输入组合的输出值。 下面的例子使用 always 语句描述了 4 个一组的反相器。当 always 语句中的 &lt;= 或 = 右边的信号发生改变时，always_comb 就重新运算 always 声明语句中的代码。always_comb 与 always 基本相同，但它避免了后者由于信号改名或添加信号所带来的错误。 module inv ( input logic [3:0] a, output logic [3:0] y ); always_comb y = ~a; endmodule = 在 always 语句中称为阻塞赋值 (blocking assignment)，与之相对的 &lt;= 称为非阻塞赋值 (non-blocking assignment)。一组阻塞赋值语句将以其在代码中出现的顺序来计算，一组非阻塞赋值语句则并行地计算。在 SystemVerilog 中，组合逻辑适合使用阻塞赋值，而在时序逻辑中需要使用非阻塞赋值。不要把使用 assign 语句的连续赋值与这两语句混淆，assign 语句必须放在 always 语句的外面，而且是并发计算。 5.1 case 语句 使用 always 语句实现组合逻辑的一个较好应用是利用 case 语句实现七段显示译码器，case 语句必须出现在 always 语句的内部，它基于输入值执行不同的动作，如果所有可能的输入组合都被定义，则 case 语句表示组合逻辑；否则，它就表示时序逻辑，因为输出会保持为未定义情况下的原来值。 下面的例子使用 case 语句描述七段显示译码器。default 子句是一种非常方便的方法，用于定义没有明确列出的所有情况下的输出，这样可以保证产生组合逻辑。 module sevenseg ( input logic [3:0] data, output logic [6:0] segments ); always_comb case(data) // abc_defg 0: segments=7'b111_1110; 1: segments=7'b011_0000; 2: segments=7'b110_1101; 3: segments=7'b111_1001; 4: segments=7'b011_0011; 5: segments=7'b101_1011; 6: segments=7'b101_1111; 7: segments=7'b111_0000; 8: segments=7'b111_1111; 9: segments=7'b111_0011; default: segments=7'b000_0000; endcase endmodule 5.2 if 语句 always 语句中可以包含 if 语句，if 语句后面还可以出现 else 语句。if 语句必须出现在 always 语句的内部。如果所有可能的输入组合都处理了，则这条语句就表示组合逻辑；否则，就产生时序逻辑。下面的例子描述了优先级电路，NNN 输入优先电路将对应的最高有效输入为 TRUE 的位设置为输出 TRUE。 module priorityckt ( input logic [3:0] a, output logic [3:0] y ); always_comb if (a[3]) y&lt;=4'b1000; else if (a[2]) y&lt;=4'b0100; else if (a[1]) y&lt;=4'b0010; else if (a[0]) y&lt;=4'b0001; else y&lt;=4'b0000; endmodule 5.3 带有无关项的真值表 真值表中可能包含无关项从而提供更多逻辑简化可能。下面的例子展示了如何利用无关项描述优先级电路。其中 casez 语句的作用与 case 语句一样，但它能识别作为无关项的 ?。 module priority_casez ( input logic [3:0] a, output logic [3:0] y ); always_comb casez(a) 4'b1???: y&lt;=4'b1000; 4'b01??: y&lt;=4'b0100; 4'b001?: y&lt;=4'b0010; 4'b0001: y&lt;=4'b0001; default: y&lt;=4'b0000; endcase endmodule 5.4 阻塞赋值和非阻塞赋值 下面将解释什么时候和怎样使用不同赋值类型的准则，如果不遵照这些准则，编写的代码就可能在模拟时正确，但综合到不正确的硬件。 使用 always_ff@ (posedge clk) 和非阻塞赋值描述同步时序逻辑 always_ff@ (posedge clk) begin n1 &lt;= d; // nonblocking q &lt;= n1; // nonblocking end 使用连续赋值描述简单组合逻辑 assign y=s ? d1 : d0; 使用 always_comb 和阻塞赋值描述复杂组合逻辑将会很有帮助 always_comb begin p = a ^ b; g = a &amp; b; s = p ^ cin; cout = g | (p &amp; cin); end 不要在多于 1 个 always 语句或者连续赋值语句中对同一个信号赋值 组合逻辑 在 2.5 节使用了阻塞赋值正确地对全加器进行了建模，现在来探讨它如何操作以及如果使用非阻塞赋值有什么不同。假设a、b、cin 都初始化为 0，因此 p、g、s 和 cout 也是 0。在某一时刻，a 改变为 1，触发 always 语句。4 个阻塞赋值按顺序计算，p 和 g 是阻塞赋值，在计算 s 和 cout 前得到新值。 1) p←1⊕0=12) g←1⋅0=03) s←1⊕0=14) cout←0+1⋅0=01) \\ \\mathrm{p} \\leftarrow 1 \\oplus 0 = 1\\\\ 2) \\ \\mathrm{g} \\leftarrow 1 \\cdot 0=0 \\\\ 3) \\ \\mathrm{s} \\leftarrow 1 \\oplus 0=1 \\\\ 4) \\ \\mathrm{cout} \\leftarrow 0+1 \\cdot 0=0 1) p←1⊕0=12) g←1⋅0=03) s←1⊕0=14) cout←0+1⋅0=0 下面的例子说明了非阻塞赋值的使用。考虑 a 从 0 上升为 1，而 b 和 cin 都为 0 的情况。4 个非阻塞赋值并发地计算。 p←1⊕0=1 g←1⋅0=0 s←0⊕0=0 cout ←0+0⋅0=0\\mathrm{p} \\leftarrow 1 \\oplus 0=1 \\quad \\mathrm{~g} \\leftarrow 1 \\cdot 0=0 \\quad \\mathrm{~s} \\leftarrow 0 \\oplus 0=0 \\quad \\text { cout } \\leftarrow 0+0 \\cdot 0=0 p←1⊕0=1 g←1⋅0=0 s←0⊕0=0 cout ←0+0⋅0=0 注意 s 与 p 并发计算，因此使用 p 的原来值，而不是新值，所以 s 保持 0 而不是 1。然而，p 从 0 改变为 1，这个改变触发 always 语句，进行第二次计算，过程如下： p←1⊕1=1 g←1⋅0=0 s←1⊕0=1 cout ←0+1⋅0=0\\mathrm{p} \\leftarrow 1 \\oplus 1=1 \\quad \\mathrm{~g} \\leftarrow 1 \\cdot 0=0 \\quad \\mathrm{~s} \\leftarrow 1 \\oplus 0=1 \\quad \\text { cout } \\leftarrow 0+1 \\cdot 0=0 p←1⊕1=1 g←1⋅0=0 s←1⊕0=1 cout ←0+1⋅0=0 这次 p 已经是 1，所以 s 正确地改变为 1。非阻塞赋值最后达到正确值，但是 always 语句必须计算两次，这使得仿真变慢。在对组合逻辑建模时，使用非阻塞赋值的另一个缺点是，如果忘记把中间变量包括在敏感信号列表中，那么 HDL 会产生错误的结果。 // nonblocking assignments (not recommended) module fulladder ( input logic a, b, cin, output logic s, cout ); logic p, g; always_comb begin p &lt;= a ^ b; g &lt;= a &amp; b; s &lt;= p ^ cin; cout &lt;= g | (p &amp; cin); end endmodule 时序逻辑 使用非阻塞式赋值可以正确地描述 4.3 节中的同步器。下面的例子尝试用阻塞赋值来描述同一个模块。假设初始化 d=0，n1=1，q=0。在 clk 的上升沿，d 复制到 n1。之后 n1 的这个新值复制到 q，导致 n1 和 q 中出现不正确的 d。在时钟沿后赋值依次进行，q = n1 = 0。 // Bad implementation of a synchronizer using blocking assignments module syncbad ( input logic clk, input logic d, output logic q ); logic n1; always_ff @(posedge clk) begin n1 = d; // blocking q = n1; // blocking end endmodule 在对时序逻辑建模时，在 always 语句中必须使用非阻塞赋值。阻塞赋值并没有优势，反而带来了未知行为的风险。有些时序电路无法使用阻塞赋值，无论顺序是什么。 6 有限状态机 有限状态机 (FSM) 由状态寄存器和两个组合逻辑块组成，用于计算当前状态和输入下的下一个状态和输出。状态机的 HDL 描述相应地划分成 3 部分来对状态寄存器、下一个状态逻辑和输出逻辑建模。 下面的例子描述了 3 分频计数器有限状态机，它提供异步复位来初始化有限状态机，状态寄存器使用触发器的普通风格，下一个状态和输出逻辑块是组合逻辑。 module divide3FSM ( input logic clk, input logic reset, output logic y ); typedef enum logic [1:0] {S0, S1, S2} statetype; statetype [1:0] state, next_state; // state register always_ff@(posedge clk, posedge reset) if (reset) state &lt;= S0; else state &lt;= next_state; // next state register always_comb case (state) S0: next_state &lt;= S1; S1: next_state &lt;= S2; S2: next_state &lt;= S0; default: next_state &lt;= S0; endcase // output logic assign y = (state == S0); endmodule typedef 语句定义了 statetype 为一个 2 位的 logic 值，它有 3 个可能的值：S0、S1、S2。state 和 next_state 都是 statetype 类型的信号。枚举编码默认为数字排序：S0=00、S1=01、S2=10。编码可以由用户显示设置，比如下面的代码将状态编码为 3 位的独热值。 typedef enum logic [2:0] {S0=3'b001, S1=3'b010, S2=3'b100} statetype; 因为下一个状态逻辑必须是组合逻辑，所以 case 语句中的 default 是必需的。 7 数据类型 在 Verilog 中，如果信号出现在 always 模块中 &lt;= 或 = 的左边，那么它必须声明为 reg。否则，它应该声明为 wire。因此，一个 reg 信号可能是一个触发器、锁存器或者组合逻辑的输出，取决于敏感信号列表和 always 模块的语句。 输入和输出端口默认为 wire 类型，除非它们的类型被明确定义为 reg。下面的例子展示了如何使用传统 Verilog 来描述触发器。其中 clk 和 d 默认为 wire 类型，而 q 则明确定义为 reg 类型，因为 q 出现在 always 模块中 &lt;= 的左边。 module flop ( input clk, input [3:0] d, output reg [3:0] q ); always @(posedge clk) q &lt;= d; endmodule SystemVerilog 引入 logic 类型，logic 类型是 reg 类型的同义词，避免误导用户它实际上是否是一个触发器的猜想。SystemVerilog 允许 logic 变量在 always 模块的外面使用，而传统语法要求在 always 模块的外面使用 wire 变量。因此，几乎所有的 SystemVerilog 信号都可以是 logic 类型，除了有多个驱动源的信号必须声明为 net 类型。 net 最常用的类型是 wire 或 tri，这两种类型是同义的，但是传统上 wire 类型用于单信号源驱动，tri 类型用于多信号源驱动。在 SystemVerilog 中，wire 类型已废弃，因为 logic 类型更常用于单驱动源信号。 当 tri 变量由一个或多个信号源驱动为某个值时，它就呈现那个值。当它未被驱动时，它呈现浮空值 (z)。当它被多个信号源驱动为不同的值时，它呈现为不确定值 (x)。同时也存在其他使用不同方法解决未驱动或者多驱动源问题的 net 类型。这些类型很少使用，但可以在任何使用 tri 类型的地方作为tri 的替代。 8 参数化模块 使用参数化模块，HDL 允许可变的位宽度。下面的例子描述了一个默认宽度为 8 的参数化的 2:1 复用器。SystemVerilog 允许在输入和输出之前使用 #(parameter...) 语句定义参数。例子中的 parameter 语句包括一个默认值，称为 width，输入和输出的位数依赖于这个参数。 module mux2 #(parameter width = 8) ( input logic [width-1:0] d0, d1, input logic s, output logic [width-1:0] y ); assign y=s ? d1 : d0; endmodule 下面的例子使用 2:1 复用器 mux2 创建一个 8 位和一个 12 位的 4:1 复用器。8 位 4:1 复用器使用它们默认宽度实例化 3 个 2:1 复用器，12 位 4:1 复用器使用 #() 重写默认宽度。 module mux4_8 ( input logic [7:0] d0, d1, d2, d3, input logic [7:0] s, output logic [7:0] y ); logic [7:0] low, hi; mux2 lowmux(d0, d1, s[0], low); mux2 himux(d2, d3, s[0], hi); mux2 outmux(low, hi, s[1], y); endmodule module mux4_12 ( input logic [11:0] d0, d1, d2, d3, input logic [1:0] s, output logic [11:0] y ); logic [11:0] low, hi; mux2 #(12) lowmux(d0, d1, s[0], low); mux2 #(12) himux(d2, d3, s[0], hi); mux2 #(12) outmux(low, hi, s[1], y); endmodule HDL 还提供 generate 语句产生基于参数值的可变数量的硬件，generate 支持 for 循环和 if 语句来确定产生多少和什么类型的硬件。下面的例子说明如何使用 generate 语句产生一个由 2 输入与门级联构成的 N 输入 AND 功能。⚠️使用 generate 语句必须注意，它很容易不经意地生成大量的硬件。 module andN #(parameter width = 8) ( input logic [width-1:0] a, output logic y ); genvar i; logic [width-1:0] x; generate assign x[0] = a[0]; for (i = 1; i &lt; width; i = i + 1) begin: forloop assign x[i] = a[i] &amp; x[i-1]; end endgenerate assign y = x[width-1]; endmodule 9 测试程序 测试程序 (testbench) 是用于测试其他模块 (称为被测设备 (Device Under Test, DUT)) 的硬件描述语言模块。测试程序包含了向被测设备提供输入的语句，以便检查是否产生理想的正确输出。输入和期待的输出模式称为测试向量 (test vector)。 考虑测试 1.1 节中计算 y=aˉbˉcˉ+abˉcˉ+abˉcy=\\bar{a} \\bar{b} \\bar{c}+a \\bar{b} \\bar{c}+a \\bar{b} cy=aˉbˉcˉ+abˉcˉ+abˉc 的 sillyfunction 模块，可以通过提供所有 8 个可能的测试向量来执行全部的测试。下面的例子说明了一个简单的测试程序，它实例化 DUT，之后提供输入。阻塞式赋值和延迟用于提供合适的输入顺序，使用者必须检查模拟结果以验证是否产生正确输出。测试程序也像其他的 HDL 模块那样被模拟，然而它们不能被综合。 module testbench1 (); logic a, b, c, y; // instantiate DUT sillyfunction dut(a, b, c, y); // apply inputs one at a time initial begin a=0; b=0; c=0; #10; c=1; #10; b=1; c=0; #10; c=1; #10; a=1; b=0; c=0; #10; c=1; #10; b=1; c=0; #10; c=1; #10; end endmodule 模拟开始时 initial 语句执行该段内的语句。在上面的例子中，它首先提供输入模式 000，然后等待 10 个时间单位。然后提供 001，等待 10 个时间单位，以此类推，直到提供了所有 8 个可能的输入。initial 语句只能在测试程序上用于模拟，不能用于综合为实际硬件的模块中。 检查输出是否正确的过程比较枯燥且容易出错，一个更好的方法是编写自检测试程序。下面的例子展示了这一做法。其中 assert 语句检查特定条件是否成立，如果不成立则执行 else 语句。else 语句中的 $error 系统任务用于输出描述 assert 错误的错误信息。在 SystemVerilog 中，可以在不包括 x 和 z 值的信号之间使用 == 或者 != 进行比较。测试程序分别使用 === 和 !== 运算符判断相等或不相等，因为这些运算符可以对包含 x 和 z 的运算数正确操作。 module testbench2(); logic a, b, c, y; // instantiate DUT sillyfunction dut(a, b, c, y); // apply inputs one at a time // checking results initial begin a=0; b=0; c=0; #10; assert (y === 1) else $error(&quot;000 failed.&quot;); c=1; #10; assert (y === 0) else $error(&quot;001 failed.&quot;); b=1; c=0; #10; assert (y === 0) else $error(&quot;010 failed.&quot;); c=1; #10; assert (y === 0) else $error(&quot;011 failed.&quot;); a=1; b=0; c=0; #10; assert (y === 1) else $error(&quot;100 failed.&quot;); c=1; #10; assert (y === 1) else $error(&quot;101 failed.&quot;); b=1; c=0; #10; assert (y === 0) else $error(&quot;110 failed.&quot;); c=1; #10; assert (y === 0) else $error(&quot;111 failed.&quot;); end endmodule 为每个测试向量编写代码依然是冗繁的工作，尤其是需要大量测试向量的模块中。一个比较好的方法是把测试向量放在一个单独的文件中。测试程序简单地从文件中读取测试向量，向 DUT 输入测试向量，检查 DUT 输出值是否与输出向量一致，重复这个过程直到测试向量文件的结尾。 下面的例子说明了这种测试程序，它使用没有敏感信号列表的 always 语句产生一个时钟，这样它会连续不断地重复运行。在模拟的开始，它从一个文本文件读取测试向量，提供两个周期的 reset 脉冲。虽然时钟信号和复位信号在组合逻辑测试中不是必需的，但它们也包含在代码中，因为它们在测试时序 DUT 中是很重要的。example.tv 是包含二进制格式输入和期待输出的文本文件： 000_1 001_0 010_0 011_0 100_1 101_1 110_0 111_0 module testbench3 (); logic clk, reset; logic a, b, c, y, yexpected; logic [31:0] vectornum, errors; logic [3:0] testvectors[10000:0]; // instantiate DUT sillyfunction dut(a, b, c, y); // generate clock always begin clk=1; #5; clk=0; #5; end // at start of test, load vectors and pulse reset initial begin $readmemb(&quot;example.tv&quot;, testvectors); vectornum=0; errors=0; reset=1; #27; reset=0; end // apply test vectors on rising edge of clk always @(posedge clk) begin #1; {a, b, c, yexpected} = testvectors[vectornum]; end // check results on falling edge of clk always @(negedge clk) if (~reset) begin // skip during reset if (y !== yexpected) begin // check result $display(&quot;Error: inputs=%b&quot;, {a, b, c}); $display(&quot; outputs=%b (%b expected)&quot;, y, yexpected); errors = errors + 1; end vectornum = vectornum + 1; if (testvectors[vectornum] === 4'bx) begin $display(&quot;%d tests complete with %d errors&quot;, vectornum, errors); $finish; end end endmodule $readmem 将二进制数字文件读入 testvectors 数组中，$readmemh 与之相似，但它读取十六进制数字的文件。代码的下一块在时钟的上沿后等待一个时间单位，然后根据当前测试向量中的 4 位设置 3 位输入 (a、b 和 c) 和期望的输出 (yexpected)。测试程序将期望的输出 yexpected 与生成的输出 y 比较，如果它们不相等则输出一条错误信息。这个进程重复直到 testvectors 数组中没有更多可用的测试向量，$finish 结束模拟。 10 总结 对于现代数字设计人员，HDL 是十分重要的工具。学会了 SystemVerilog 或者 VHDL，就可以比手工绘制图表更快地描述数字系统。而且因为修改时只需要修改代码，而不是烦琐地重绘电路图，所以调试周期也会很快。 硬件描述语言用于模拟和综合。在系统转化为硬件前逻辑模拟是在计算机上进行测试的有效方法。模拟器可以检测物理硬件中不可能被测量的系统中的信号值。逻辑综合把硬件描述语言代码转换成数字逻辑电路。 最重要的是：编写 HDL 代码是描述一个真实存在的硬件，而不是编写一个软件程序。很多初学者的常见错误是不考虑准备产生的硬件而编写 HDL 代码。应该从画系统的结构图开始，区分哪些部分是组合逻辑，哪些部分是时序逻辑或者有限状态机。然后使用可以描述目标硬件的正确风格为每一个部分编写 HDL 代码。 ","link":"https://SylvanasQAQ.github.io/post/PGELKesQU/"},{"title":"第 6 章家庭作业","content":"6.22 假设每条磁道的位数 (bits per track, bpt) 与圆洞的半径成正比，即 bpt=α⋅(x⋅r)\\text{bpt} = \\alpha \\cdot (x \\cdot r)bpt=α⋅(x⋅r)；总的磁道数 (track number, tn) 与盘面可用半径成正比，即 tn=β⋅(1−x)r\\text{tn} = \\beta \\cdot (1-x)rtn=β⋅(1−x)r，则磁盘的容量 (capacity, c) 可以表示为 c=bpt⋅tn=αβ⋅r2(1−x)xc = \\text{bpt} \\cdot \\text{tn} = \\alpha \\beta \\cdot r^2 (1-x) x c=bpt⋅tn=αβ⋅r2(1−x)x 其中 α\\alphaα、β\\betaβ 和 rrr 均为常数，因此 c∝x−x2c \\propto x - x^2c∝x−x2。当 x=12x = \\frac{1}{2}x=21​ 时，ccc 取得最大值 14r2⋅α⋅β\\frac{1}{4} r^2 \\cdot \\alpha \\cdot \\beta41​r2⋅α⋅β。 6.23 该磁盘的平均旋转延迟为 Tavg rotation=12×(60 s/15000 RPM)×1000 ms/s≈2 msT_{\\text{avg rotation}} = \\frac{1}{2} \\times (60 \\text{ s}/15000 \\text{ RPM}) \\times 1000 \\text{ ms/s} \\approx 2 \\text{ ms}Tavg rotation​=21​×(60 s/15000 RPM)×1000 ms/s≈2 ms。 扇区的平均传送时间为 Tavg transfer=60 s/15000 RPM×1/800 扇区/磁道×1000 ms/s≈0.005 msT_{\\text{avg transfer}} = 60 \\text{ s}/15000 \\text{ RPM} \\times 1/800 \\text{ 扇区/磁道} \\times 1000 \\text{ ms/s} \\approx 0.005 \\text{ ms}Tavg transfer​=60 s/15000 RPM×1/800 扇区/磁道×1000 ms/s≈0.005 ms。 因此访问扇区的平均时间为 Taccess=Tavg seek+Tavg rotation+Tavg transfer=6.005 msT_{\\text{access}} = T_{\\text{avg seek}} + T_{\\text{avg rotation}} + T_{\\text{avg transfer}} = 6.005 \\text{ ms} Taccess​=Tavg seek​+Tavg rotation​+Tavg transfer​=6.005 ms 6.24 A. 对第一个块定位读/写头的时间为 Tavg seek+Tavg rotation=6 msT_{\\text{avg seek}} + T_{\\text{avg rotation}} = 6 \\text{ ms}Tavg seek​+Tavg rotation​=6 ms (参照 6.23)，当逻辑块被映射到连续的扇区上时为最优情况，此时的传送时间为 (1 MB≈1000 KB1 \\text{ MB} \\approx 1000 \\text{ KB}1 MB≈1000 KB)： Ttransfer=(2 MB/512 B)×60 s/15000 RPM×1/1000 扇区/磁道×1000 ms/s=16 msT_{\\text{transfer}} = (2 \\text{ MB}/ 512 \\text{ B}) \\times 60 \\text{ s}/15000 \\text{ RPM} \\times 1/1000 \\text{ 扇区/磁道} \\times 1000 \\text{ ms/s} = 16 \\text{ ms} Ttransfer​=(2 MB/512 B)×60 s/15000 RPM×1/1000 扇区/磁道×1000 ms/s=16 ms 所以读该文件所需要的最优时间为 Taccess=Tavg seek+Tavg rotation+Ttransfer=22 msT_{\\text{access}} = T_{\\text{avg seek}} + T_{\\text{avg rotation}} + T_{\\text{transfer}} = 22 \\text{ ms}Taccess​=Tavg seek​+Tavg rotation​+Ttransfer​=22 ms。 B. 如果块是随机映射到磁盘扇区上的，那么对每个逻辑块的读都需要重新定位读/写头，但总的数据传送时间不变，因此总时间为： Taccess=(2 MB/512 B)×(Tavg seek+Tavg rotation)+Ttransfer=24022 msT_{\\text{access}} = (2 \\text{ MB}/ 512 \\text{ B}) \\times (T_{\\text{avg seek}} + T_{\\text{avg rotation}}) + T_{\\text{transfer}} = 24022 \\text{ ms} Taccess​=(2 MB/512 B)×(Tavg seek​+Tavg rotation​)+Ttransfer​=24022 ms 6.25 高速缓存 m C B E S t s b 1 32 1024 4 4 64 24 6 2 2 32 1024 4 256 1 30 0 2 3 32 1024 8 1 128 22 7 3 4 32 1024 8 128 1 29 0 3 5 32 1024 32 1 32 22 5 5 6 32 1024 32 4 8 24 3 5 6.26 高速缓存 m C B E S t s b 1 32 2048 8 1 256 21 8 3 2 32 2048 4 4 128 23 7 2 3 32 1024 2 8 64 25 6 1 4 32 1024 32 2 16 23 4 5 6.27 A. 组索引=1\\text{组索引} = 1组索引=1，有效标记位=45 or 38\\text{有效标记位} = \\text{45 or 38}有效标记位=45 or 38，会在组 1 中命中的十六进制内存地址为 0x08A4∼\\sim∼0x08A7，0x0704∼\\sim∼0x0707。 B. 组索引=6\\text{组索引} = 6组索引=6，有效标记位=91\\text{有效标记位} = 91有效标记位=91，会在组 6 中命中的十六进制内存地址为 0x1238∼\\sim∼0x123B。 6.28 A. 第二组的有效位均为 0，因此没有地址会在组 2 命中。 B. 组索引=4\\text{组索引} = 4组索引=4，有效标记位=C7 or 05\\text{有效标记位} = \\text{C7 or 05}有效标记位=C7 or 05，会在组 4 中命中的十六进制内存地址为 0x18F0∼\\sim∼0x18F3，0x00B0∼\\sim∼0x00B3。 C. 组索引=5\\text{组索引} = 5组索引=5，有效标记位=71\\text{有效标记位} = 71有效标记位=71，会在组 5 中命中的十六进制内存地址为 0x0E34∼\\sim∼0x0E37。 D. 组索引=7\\text{组索引} = 7组索引=7，有效标记位=DE\\text{有效标记位} = \\text{DE}有效标记位=DE，会在组 7 中命中的十六进制内存地址为 0x1BDC∼\\sim∼0x1BDF。 6.29 A. 11 10 9 8 7 6 5 4 3 2 1 0 CT CT CT CT CT CT CT CT CI CI CO CO B. 操作 地址 命中？ 读出的值 (或者未知) 读 0x834 否 - 写 0x836 否 未知 读 0xFFD 是 C0 6.30 A. 高速缓存的大小 C=S×E×B=128C = S \\times E \\times B = 128C=S×E×B=128 字节。 B. 12 11 10 9 8 7 6 5 4 3 2 1 0 CT CT CT CT CT CT CT CT CI CI CI CO CO 6.31 A. 12 11 10 9 8 7 6 5 4 3 2 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 B. 参数 值 高速缓存块偏移 (CO) 0x02 高速缓存组索引 (CI) 0x06 高速缓存标记 (CT) 0x38 高速缓存命中？(是/否) 是 返回的高速缓存字节 0xEB 6.32 A. 12 11 10 9 8 7 6 5 4 3 2 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 B. 参数 值 高速缓存块偏移 (CO) 0x00 高速缓存组索引 (CI) 0x02 高速缓存标记 (CT) 0xB7 高速缓存命中？(是/否) 否 返回的高速缓存字节 - 6.33 会在组 2 中命中的 8 个内存地址为 0x1788∼\\sim∼0x178B 和 0x16C8∼\\sim∼0x16CB。 6.34 dest 数组的命中情况如下： 列0 列1 列2 列3 行0 m m m m 行1 m m m m 行2 m m m m 行3 m m m m src 数组的命中情况如下： 列0 列1 列2 列3 行0 m m h m 行1 m h m h 行2 m m h m 行3 m h m h 6.35 dest 数组的命中情况如下： 列0 列1 列2 列3 行0 m h h h 行1 m h h h 行2 m h h h 行3 m h h h src 数组的命中情况如下： 列0 列1 列2 列3 行0 m h h h 行1 m h h h 行2 m h h h 行3 m h h h 6.36 A. x[0][i] 和 x[1][i] 被映射到 cache 相同的组中，因此不命中率为 100100100%。 B. x[0][i] 和 x[1][i] 会被映射到不同的组中，不命中率为 252525%。 C. x[0][i] 和 x[1][i] 会被映射到同一个组但是不同行中，不命中率为 252525%。 D. 不会，因为更大的高速缓存大小也无法减少冷不命中的次数，所以不命中率不变。 E. 可以，因为更大的块大小减少了冷不命中的次数，不命中率下降。 6.37 函数 N=64 N=60 sumA 25% 25% sumB 100% 25% sumC 50% 25% 6.38 A. 写总数为 4×16×16=10244 \\times 16 \\times 16 = 10244×16×16=1024。 B. 在高速缓存中不命中的写总数是 4×16×16÷8=1284 \\times 16 \\times 16 \\div 8 = 1284×16×16÷8=128。 C. 不命中率是 12.512.512.5%。 6.39 A. 写总数为 4×16×16=10244 \\times 16 \\times 16 = 10244×16×16=1024。 B. 在高速缓存中不命中的写总数是 4×16×16÷4=2564 \\times 16 \\times 16 \\div 4 = 2564×16×16÷4=256。 C. 不命中率是 252525%。 6.40 A. 写总数为 4×16×16=10244 \\times 16 \\times 16 = 10244×16×16=1024。 B. 在高速缓存中不命中的写总数是 16×16÷2+16×16÷2=25616 \\times 16 \\div 2 + 16 \\times 16 \\div 2= 25616×16÷2+16×16÷2=256。 C. 不命中率是 252525%。 6.41 高速缓存每行只能容纳一个 pixel 结构体，因此会有 252525% 的写在高速缓存中不命中。 6.42 高速缓存每次加载 4 个 char，有 1 个 char 因为冷不命中 miss，因此还是会有 252525% 的写在高速缓存中不命中。 6.43 高速缓存每次加载 1 个 int，且由于冷不命中 miss，因此 100100100% 的写在高速缓存中不命中。 6.44 从 CSAPP 官网下载 mountain 压缩包，解压后 make 并运行，得到以下结果： Clock frequency is approx. 2300.0 MHz Memory mountain (MB/sec) s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 s13 s14 s15 128m 18742 9757 6592 4387 3415 2935 2559 2252 2176 2093 2111 2085 2037 2071 1908 64m 19037 10054 6670 4472 3486 2967 2634 2344 2281 2246 2284 2215 2141 2104 2087 32m 19291 10480 7094 4870 3623 3216 2840 2522 2490 2405 2414 2395 2378 2424 2387 16m 20314 12228 8378 6339 4620 4286 3196 2886 2857 2896 2943 3088 3133 3253 3261 8m 22539 15352 12114 10344 8913 7677 6621 5791 5534 5837 5808 6055 6867 7412 7123 4m 39694 28494 22420 17825 14470 12300 10733 9434 8657 8119 7782 7488 7330 7201 7065 2m 39689 28433 22435 17799 14494 12287 10735 9429 8654 8148 7770 7488 7308 7191 7104 1024k 39629 28475 22450 17911 14529 12354 10742 9458 8692 8304 8098 8080 8136 8445 8639 512k 40971 31511 29140 27366 24465 21376 18773 16542 17455 21877 20912 23175 22438 23637 23087 256k 42116 32825 32615 32444 31370 29765 27767 25635 24794 24669 24317 24509 24055 23636 23207 128k 42139 32839 32732 32153 31337 29942 27677 24890 25222 24791 23997 24484 24055 23767 23315 64k 41893 32825 32084 31881 30824 29484 28037 24533 24341 28545 42816 45508 44939 44489 43313 32k 49324 49067 48124 47104 45397 45181 44860 43615 43155 43303 43351 40773 40817 40773 39867 16k 48312 47104 45508 44022 44322 41860 42047 38610 38055 36935 35674 34125 35341 32817 33941 编写 Python 脚本对数据进行可视化： import matplotlib.pyplot as plt import numpy as np data = [] for line in open(&quot;output.txt&quot;,&quot;r&quot;): line = line.replace(&quot;\\t&quot;, &quot; &quot;) line = line.split(&quot; &quot;) if line[0].endswith(&quot;k&quot;) or line[0].endswith(&quot;m&quot;): if line[0] == &quot;Clock&quot;: continue data.append([int(i) for i in line[1:-1]]) data = np.array(data) X_LEN = data.shape[1] Y_LEN = data.shape[0] fig = plt.figure(figsize=(8,8)) ax = plt.axes(projection='3d') X = np.arange(1, X_LEN+1, 1) Y = np.arange(1, Y_LEN+1, 1) X, Y = np.meshgrid(X, Y) ax.plot_surface(X, Y, data,cmap='plasma', edgecolor='none') ax.set(xlim=(1,X_LEN), ylim=(1,Y_LEN), xlabel='Stride (x8 bytes)', ylabel='Size (byte)', zlabel='\\nread throughput (MB/s)') ax.set_xticks(np.arange(1, X_LEN+1, 2)) ax.set_xticklabels(['s1', 's3', 's5', 's7', 's9', 's11', 's13', 's15']) ax.set_yticks(np.arange(1, Y_LEN+1, 2)) ax.set_yticklabels(['128m', '32m', '8m', '2m', '512k', '128k', '32k']) ax.set_zticks([5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]) ax.text(X_LEN-2, 13, data[13-1][X_LEN-3], &quot;L1 cache (~64k)&quot;, color='red') ax.text(X_LEN-2, 9, data[9-1][X_LEN-3], &quot;L2 cache (512k)&quot;, color='blue') ax.text(X_LEN-2, 5, data[5-1][X_LEN-3], &quot;L3 cache (8M)&quot;, color='red') plt.show() 在 Mac 终端输入 system_profiler SPHardwareDataType | grep Cache 和 sysctl machdep.cpu.brand_string 分别得到以下输出： // Output of `system_profiler SPHardwareDataType | grep Cache` L2 Cache (per Core): 512 KB L3 Cache: 8 MB // Output of `sysctl machdep.cpu.brand_string` machdep.cpu.brand_string: Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 在 EatYourBytes 上查得 i7-1068NG7 的 L1 Cache 的大小为 80 KB。 因为原始版本的步长不够短，所以从存储器山中只能得出 L1 Cache 约为 64 KB。为得到准确的 L1 Cache，对 mountain.c 文件进行修改： /* $begin mountainmain */ // from 224k to 16k for (size = 14*MINBYTES; size &gt;= MINBYTES; size -= MINBYTES) { /* $end mountainmain */ 重新编译运行，利用输出结果绘制出存储器山的图像，可以清楚地看到 L1 Cache 的山脊线在 80 KB： 6.45 因为转置运算大部分为内存操作，运算操作较少，因此很难从算法角度去优化。下面尝试通过循环展开去尽量最大化利用高速缓存（以下提到的 axb loop unrolling 指对变量 i 进行 ×a\\times a×a 展开，对变量 j 进行 ×b\\times b×b 展开） #include &lt;assert.h&gt; #include &lt;memory.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; void transpose(int *dst, int *src, int dim) { int i, j; for (i = 0; i &lt; dim; i++) for (j = 0; j &lt; dim; j++) dst[j * dim + i] = src[i * dim + j]; } // use 4x8 loop unrolling void transpose_4x8(int *dst, int *src, int dim) { int i, j, k; int dim2 = dim * 2; int dim3 = dim * 3; int dim4 = dim * 4; int dim5 = dim * 5; int dim6 = dim * 6; int dim7 = dim * 7; for (i = 0; i &lt;= dim - 4; i += 4) { for (j = 0; j &lt;= dim - 8; j += 8) { int dst_offset = j * dim + i; int dst_offset2 = dst_offset + 1; int dst_offset3 = dst_offset + 2; int dst_offset4 = dst_offset + 3; int src_offset = i * dim + j; int src_offset2 = src_offset + dim; int src_offset3 = src_offset + dim2; int src_offset4 = src_offset + dim3; dst[dst_offset] = src[src_offset]; dst[dst_offset2] = src[src_offset2]; dst[dst_offset3] = src[src_offset3]; dst[dst_offset4] = src[src_offset4]; dst[dst_offset + dim] = src[src_offset + 1]; dst[dst_offset2 + dim] = src[src_offset2 + 1]; dst[dst_offset3 + dim] = src[src_offset3 + 1]; dst[dst_offset4 + dim] = src[src_offset4 + 1]; dst[dst_offset + dim2] = src[src_offset + 2]; dst[dst_offset2 + dim2] = src[src_offset2 + 2]; dst[dst_offset3 + dim2] = src[src_offset3 + 2]; dst[dst_offset4 + dim2] = src[src_offset4 + 2]; dst[dst_offset + dim3] = src[src_offset + 3]; dst[dst_offset2 + dim3] = src[src_offset2 + 3]; dst[dst_offset3 + dim3] = src[src_offset3 + 3]; dst[dst_offset4 + dim3] = src[src_offset4 + 3]; dst[dst_offset + dim4] = src[src_offset + 4]; dst[dst_offset2 + dim4] = src[src_offset2 + 4]; dst[dst_offset3 + dim4] = src[src_offset3 + 4]; dst[dst_offset4 + dim4] = src[src_offset4 + 4]; dst[dst_offset + dim5] = src[src_offset + 5]; dst[dst_offset2 + dim5] = src[src_offset2 + 5]; dst[dst_offset3 + dim5] = src[src_offset3 + 5]; dst[dst_offset4 + dim5] = src[src_offset4 + 5]; dst[dst_offset + dim6] = src[src_offset + 6]; dst[dst_offset2 + dim6] = src[src_offset2 + 6]; dst[dst_offset3 + dim6] = src[src_offset3 + 6]; dst[dst_offset4 + dim6] = src[src_offset4 + 6]; dst[dst_offset + dim7] = src[src_offset + 7]; dst[dst_offset2 + dim7] = src[src_offset2 + 7]; dst[dst_offset3 + dim7] = src[src_offset3 + 7]; dst[dst_offset4 + dim7] = src[src_offset4 + 7]; } for (k = j; k &lt; dim; k++) { int dst_offset = k * dim + i; int src_offset = i * dim + k; dst[dst_offset] = src[src_offset]; dst[dst_offset + 1] = src[src_offset + dim]; dst[dst_offset + 2] = src[src_offset + dim2]; dst[dst_offset + 3] = src[src_offset + dim3]; } } for (; i &lt; dim; i++) for (j = 0; j &lt; dim; j++) dst[j * dim + i] = src[i * dim + j]; } // use 2x8 loop unrolling void transpose_2x8(int *dst, int *src, int dim) { int i, j, k; int dim2 = dim * 2; int dim3 = dim * 3; int dim4 = dim * 4; int dim5 = dim * 5; int dim6 = dim * 6; int dim7 = dim * 7; for (i = 0; i &lt;= dim - 2; i += 2) { for (j = 0; j &lt;= dim - 8; j += 8) { int dst_offset = j * dim + i; int dst_offset2 = dst_offset + 1; int src_offset = i * dim + j; int src_offset2 = src_offset + dim; dst[dst_offset] = src[src_offset]; dst[dst_offset2] = src[src_offset2]; dst[dst_offset + dim] = src[src_offset + 1]; dst[dst_offset2 + dim] = src[src_offset2 + 1]; dst[dst_offset + dim2] = src[src_offset + 2]; dst[dst_offset2 + dim2] = src[src_offset2 + 2]; dst[dst_offset + dim3] = src[src_offset + 3]; dst[dst_offset2 + dim3] = src[src_offset2 + 3]; dst[dst_offset + dim4] = src[src_offset + 4]; dst[dst_offset2 + dim4] = src[src_offset2 + 4]; dst[dst_offset + dim5] = src[src_offset + 5]; dst[dst_offset2 + dim5] = src[src_offset2 + 5]; dst[dst_offset + dim6] = src[src_offset + 6]; dst[dst_offset2 + dim6] = src[src_offset2 + 6]; dst[dst_offset + dim7] = src[src_offset + 7]; dst[dst_offset2 + dim7] = src[src_offset2 + 7]; } for (k = j; k &lt; dim; k++) { int dst_offset = k * dim + i; int src_offset = i * dim + k; dst[dst_offset] = src[src_offset]; dst[dst_offset + 1] = src[src_offset + dim]; } } for (; i &lt; dim; i++) for (j = 0; j &lt; dim; j++) dst[j * dim + i] = src[i * dim + j]; } // use 1x4 loop unrolling void transpose_1x4(int *dst, int *src, int dim) { int i, j; int dim2 = dim * 2; int dim3 = dim * 3; for (i = 0; i &lt; dim; i++) { for (j = 0; j &lt;= dim - 4; j += 4) { int dst_offset = j * dim + i; int src_offset = i * dim + j; dst[dst_offset] = src[src_offset]; dst[dst_offset + dim] = src[src_offset + 1]; dst[dst_offset + dim2] = src[src_offset + 2]; dst[dst_offset + dim3] = src[src_offset + 3]; } for (; j &lt; dim; j++) dst[j * dim + i] = src[i * dim + j]; } } #define N 2048 #define LOOP 50 int main() { for (int num = 4, len, size; num &gt;= -4; num--) { len = N + num; size = len * len; int *space1 = (int *)malloc(size * sizeof(int)); for (int i = 0; i &lt; size; i++) space1[i] = i; int *space2 = (int *)malloc(size * sizeof(int)); int *space3 = (int *)malloc(size * sizeof(int)); int *space4 = (int *)malloc(size * sizeof(int)); int *space5 = (int *)malloc(size * sizeof(int)); printf(&quot;N = %d\\t&quot;, len); clock_t start, end; start = clock(); for (int i = 0; i &lt; LOOP; i++) transpose_1x4(space3, space1, len); end = clock(); printf(&quot;1x4: %ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) transpose_2x8(space4, space1, len); end = clock(); printf(&quot;2x8: %ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) transpose_4x8(space5, space1, len); end = clock(); printf(&quot;4x8: %ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) transpose(space2, space1, len); end = clock(); printf(&quot;base: %ld\\n&quot;, end - start); assert(memcmp(space2, space3, len * sizeof(int)) == 0); assert(memcmp(space2, space4, len * sizeof(int)) == 0); assert(memcmp(space2, space5, len * sizeof(int)) == 0); free(space1); free(space2); free(space3); free(space4); free(space5); } } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 平台上测试得到以下输出： N = 2052 1x4: 442347 | 2x8: 306081 | 4x8: 282073 | base: 559574 N = 2051 1x4: 399215 | 2x8: 293979 | 4x8: 268137 | base: 522580 N = 2050 1x4: 399677 | 2x8: 286348 | 4x8: 264988 | base: 496756 N = 2049 1x4: 560932 | 2x8: 316974 | 4x8: 273297 | base: 1231977 N = 2048 1x4: 953632 | 2x8: 644103 | 4x8: 376935 | base: 1517008 N = 2047 1x4: 536301 | 2x8: 292933 | 4x8: 289311 | base: 1211034 N = 2046 1x4: 409470 | 2x8: 291104 | 4x8: 259760 | base: 500450 N = 2045 1x4: 386963 | 2x8: 306163 | 4x8: 262260 | base: 498458 N = 2044 1x4: 403452 | 2x8: 299026 | 4x8: 257768 | base: 509572 可以观察到当 N=2047,2048,2049N = 2047, 2048, 2049N=2047,2048,2049 时，原始版本的转置函数用时翻了一倍以上，这可能是高速缓存的冲突不命中导致的。还可发现，随着循环展开程度的提高，缓存利用率提升，因此耗时降低。而且循环展开程度越高，转置函数对不同大小矩阵的适应性就越好。 6.46 同 6.45，将有向图转换成其对应的无向图也大部分为内存操作，采用循环展开最大化利用高速缓存。下面的 axbd 指对变量 i 进行 ×a\\times a×a 展开，对变量 j 进行 ×b\\times b×b 展开，d 表示同时更新 dst 和 src。 #include &lt;assert.h&gt; #include &lt;memory.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; void col_convert(int *G, int dim) { int i, j; for (i = 0; i &lt; dim; i++) for(j = 0; j &lt; dim; j++) G[j*dim + i] = G[i*dim + j] || G[j*dim + i]; } void col_convert_1x4(int *G, int dim) { int i, j; int dim2 = dim*2; int dim3 = dim*3; for (i = 0; i &lt; dim; i++) { for (j = 0; j &lt;= dim-4; j+=4) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[dst_offset] = G[dst_offset] || G[src_offset]; G[dst_offset+dim] = G[dst_offset+dim] || G[src_offset+1]; G[dst_offset+dim2] = G[dst_offset+dim2] || G[src_offset+2]; G[dst_offset+dim3] = G[dst_offset+dim3] || G[src_offset+3]; } for (; j &lt; dim; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[dst_offset] = G[dst_offset] || G[src_offset]; } } } void col_convert_1x4d(int *G, int dim) { int i, j; int dim2 = dim*2; int dim3 = dim*3; for (i = 0; i &lt; dim; i++) { for (j = 0; j &lt;= i-4; j+=4) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[src_offset] = G[dst_offset] = G[dst_offset] || G[src_offset]; G[src_offset+1] = G[dst_offset+dim] = G[dst_offset+dim] || G[src_offset+1]; G[src_offset+2] = G[dst_offset+dim2] = G[dst_offset+dim2] || G[src_offset+2]; G[src_offset+3] = G[dst_offset+dim3] = G[dst_offset+dim3] || G[src_offset+3]; } for (; j &lt;= i; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[src_offset] = G[dst_offset] = G[dst_offset] || G[src_offset]; } } } void col_convert_2x4(int *G, int dim) { int i, j; int dim2 = dim*2; int dim3 = dim*3; for (i = 0; i &lt;= dim-2; i+=2) { for (j = 0; j &lt;= dim-4; j+=4) { int dst_offset = j*dim + i; int src_offset = i*dim + j; int dst_offset2 = dst_offset + 1; int src_offset2 = src_offset + dim; G[dst_offset] = G[dst_offset] || G[src_offset]; G[dst_offset+dim] = G[dst_offset+dim] || G[src_offset+1]; G[dst_offset+dim2] = G[dst_offset+dim2] || G[src_offset+2]; G[dst_offset+dim3] = G[dst_offset+dim3] || G[src_offset+3]; G[dst_offset2] = G[dst_offset2] || G[src_offset2]; G[dst_offset2+dim] = G[dst_offset2+dim] || G[src_offset2+1]; G[dst_offset2+dim2] = G[dst_offset2+dim2] || G[src_offset2+2]; G[dst_offset2+dim3] = G[dst_offset2+dim3] || G[src_offset2+3]; } for (; j &lt; dim; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[dst_offset] = G[dst_offset] || G[src_offset]; G[dst_offset+1] = G[dst_offset+1] || G[src_offset+dim]; } } for (; i &lt; dim; i++) { for (j = 0; j &lt; dim; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[dst_offset] = G[dst_offset] || G[src_offset]; } } } void col_convert_2x4d(int *G, int dim) { int i, j; int dim2 = dim*2; int dim3 = dim*3; for (i = 0; i &lt;= dim-2; i+=2) { for (j = 0; j &lt;= i-4; j+=4) { int dst_offset = j*dim + i; int src_offset = i*dim + j; int dst_offset2 = dst_offset + 1; int src_offset2 = src_offset + dim; G[src_offset] = G[dst_offset] = G[dst_offset] || G[src_offset]; G[src_offset+1] = G[dst_offset+dim] = G[dst_offset+dim] || G[src_offset+1]; G[src_offset+2] = G[dst_offset+dim2] = G[dst_offset+dim2] || G[src_offset+2]; G[src_offset+3] = G[dst_offset+dim3] = G[dst_offset+dim3] || G[src_offset+3]; G[src_offset2] = G[dst_offset2] = G[dst_offset2] || G[src_offset2]; G[src_offset2+1] = G[dst_offset2+dim] = G[dst_offset2+dim] || G[src_offset2+1]; G[src_offset2+2] = G[dst_offset2+dim2] = G[dst_offset2+dim2] || G[src_offset2+2]; G[src_offset2+3] = G[dst_offset2+dim3] = G[dst_offset2+dim3] || G[src_offset2+3]; } for (; j &lt;= i; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[src_offset] = G[dst_offset] = G[dst_offset] || G[src_offset]; G[src_offset+dim] = G[dst_offset+1] = G[dst_offset+1] || G[src_offset+dim]; } } for (; i &lt; dim; i++) { for (j = 0; j &lt;= i; j++) { int dst_offset = j*dim + i; int src_offset = i*dim + j; G[src_offset] = G[dst_offset] = G[dst_offset] || G[src_offset]; } } } #define N 1024 #define LOOP 100 int main() { for(int num = -4; num &lt;= 4; num++) { int len = N + num; int size = len*len; int *space1 = (int*)malloc(size*sizeof(int)); for(int i = 0; i &lt; size; i++) space1[i] = rand() % 13 == 0 ? 1 : 0; int *space2 = (int*)malloc(size*sizeof(int)); int *space3 = (int*)malloc(size*sizeof(int)); int *space4 = (int*)malloc(size*sizeof(int)); int *space5 = (int*)malloc(size*sizeof(int)); memcpy(space2, space1, size*sizeof(int)); memcpy(space3, space1, size*sizeof(int)); memcpy(space4, space1, size*sizeof(int)); memcpy(space5, space1, size*sizeof(int)); clock_t start, end; printf(&quot;N=%d\\t&quot;, len); start = clock(); for(int i = 0; i &lt; LOOP; i++) col_convert(space1, len); end = clock(); printf(&quot;base: %lu | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) col_convert_1x4(space2, len); end = clock(); printf(&quot;1x4: %lu | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) col_convert_1x4d(space5, len); end = clock(); printf(&quot;1x4d: %lu | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) col_convert_2x4(space3, len); end = clock(); printf(&quot;2x4: %lu | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) col_convert_2x4d(space4, len); end = clock(); printf(&quot;2x4d: %lu\\n&quot;, end - start); assert(memcmp(space1, space2, size*sizeof(int)) == 0); assert(memcmp(space1, space3, size*sizeof(int)) == 0); assert(memcmp(space1, space4, size*sizeof(int)) == 0); assert(memcmp(space1, space5, size*sizeof(int)) == 0); free(space1); free(space2); free(space3); free(space4); free(space5); } } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 平台上测试得到以下输出： N=1020 base: 535192 | 1x4: 462210 | 1x4d: 251206 | 2x4: 398742 | 2x4d: 217055 N=1021 base: 503793 | 1x4: 479376 | 1x4d: 246278 | 2x4: 389119 | 2x4d: 203354 N=1022 base: 501356 | 1x4: 476889 | 1x4d: 245754 | 2x4: 394216 | 2x4d: 211496 N=1023 base: 510265 | 1x4: 455410 | 1x4d: 257818 | 2x4: 400418 | 2x4d: 215831 N=1024 base: 610578 | 1x4: 598900 | 1x4d: 317304 | 2x4: 496781 | 2x4d: 259734 N=1025 base: 495296 | 1x4: 527643 | 1x4d: 237458 | 2x4: 401026 | 2x4d: 223258 N=1026 base: 529399 | 1x4: 470104 | 1x4d: 249816 | 2x4: 391803 | 2x4d: 215337 N=1027 base: 523340 | 1x4: 470865 | 1x4d: 247452 | 2x4: 387347 | 2x4d: 223089 N=1028 base: 509739 | 1x4: 451330 | 1x4d: 252784 | 2x4: 381440 | 2x4d: 202910 可以观察到随着循环展开程度的提高，耗时逐步降低，采用同时更新 dst 和 src 后更是将耗时降为之前的一半。 ","link":"https://SylvanasQAQ.github.io/post/0_rHJUypa/"},{"title":"第 5 章家庭作业","content":"5.13 A. B. 对于数据类型 double，决定 CPE 下界的是浮点加法单元，CPE 为 3.03.03.0 C. 对于整数数据，决定 CPE 下界的是整数加法单元，CPE 为 1.01.01.0 D. 因为乘法操作之间不具有数据相关，可完全流水线化，所以关键路径上只有浮点加法，因此 CPE 为 3.003.003.00 5.14 A. 6×16 \\times 16×1 循环展开版本的关键路径上的每个部分有 666 个加法操作，共有 n/6n/6n/6 个部分，因此关键路径上的操作数为 6∗n/6=n6 * n / 6 = n6∗n/6=n，所以 CPE 约等于加法操作的延迟。而加法操作的最小延迟为 111，因此任何版本的内积过程都不能达到比 1.001.001.00 更小的 CPE。 B. 同上 5.15 #include &lt;assert.h&gt; #include &lt;memory.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; /* Definition of vector structure */ typedef double data_t; typedef struct { long len; data_t *data; } vec_rec, *vec_ptr; vec_ptr new_vec(long len) { // Allocate header structure vec_ptr pHeader = (vec_ptr)malloc(sizeof(vec_rec)); data_t *pData = NULL; if (!pHeader) return NULL; // Couldn't allocate storage pHeader-&gt;len = len; // Allocate array if (len &gt; 0) { pData = (data_t *)calloc(len, sizeof(data_t)); if (!pData) { free((void *)pHeader); return NULL; // Couldn't allocate storage } } // Data will either be NULL or allocated array pHeader-&gt;data = pData; return pHeader; } int get_vec_element(vec_ptr v, long index, data_t *dest) { if (index &lt; 0 || index &gt;= v-&gt;len) return 0; // Out of bounds *dest = v-&gt;data[index]; return 1; // Success } long vec_length(vec_ptr v) { return v-&gt;len; } data_t *get_vec_start(vec_ptr v) { return v-&gt;data; } /* Inner product. Accumulate in temporary */ void inner4(vec_ptr u, vec_ptr v, data_t *dest) { long i; long length = vec_length(u); data_t *udata = get_vec_start(u); data_t *vdata = get_vec_start(v); data_t sum = (data_t)0; for (i = 0; i &lt; length; i++) sum = sum + udata[i] * vdata[i]; *dest = sum; } /* Inner product. 6x1 loop unrolling */ void inner_6_1(vec_ptr u, vec_ptr v, data_t *dest) { long i; long length = vec_length(u); data_t *udata = get_vec_start(u); data_t *vdata = get_vec_start(v); data_t sum = (data_t)0; for (i = 0; i &lt;= length - 6; i += 6) { sum += udata[i] * vdata[i]; sum += udata[i + 1] * vdata[i + 1]; sum += udata[i + 2] * vdata[i + 2]; sum += udata[i + 3] * vdata[i + 3]; sum += udata[i + 4] * vdata[i + 4]; sum += udata[i + 5] * vdata[i + 5]; } for (; i &lt; length; i++) sum = sum + udata[i] * vdata[i]; *dest = sum; } /* Inner product. 6x6 loop unrolling */ void inner_6_6(vec_ptr u, vec_ptr v, data_t *dest) { long i; long length = vec_length(u); data_t *udata = get_vec_start(u); data_t *vdata = get_vec_start(v); data_t sum0 = (data_t)0; data_t sum1 = (data_t)0; data_t sum2 = (data_t)0; data_t sum3 = (data_t)0; data_t sum4 = (data_t)0; data_t sum5 = (data_t)0; for (i = 0; i &lt;= length - 6; i += 6) { sum0 = sum0 + (udata[i] * vdata[i]); sum1 = sum1 + (udata[i + 1] * vdata[i + 1]); sum2 = sum2 + (udata[i + 2] * vdata[i + 2]); sum3 = sum3 + (udata[i + 3] * vdata[i + 3]); sum4 = sum4 + (udata[i + 4] * vdata[i + 4]); sum5 = sum5 + (udata[i + 5] * vdata[i + 5]); } for (; i &lt; length; i++) sum0 = sum0 + udata[i] * vdata[i]; *dest = sum0 + sum1 + sum2 + sum3 + sum4 + sum5; } /* Inner product. 6x1a loop unrolling */ void inner_6_1a(vec_ptr u, vec_ptr v, data_t *dest) { long i; long length = vec_length(u); data_t *udata = get_vec_start(u); data_t *vdata = get_vec_start(v); data_t sum = (data_t)0; for (i = 0; i &lt;= length - 6; i += 6) sum = sum + (udata[i] * vdata[i] + udata[i + 1] * vdata[i + 1] + udata[i + 2] * vdata[i + 2] + udata[i + 3] * vdata[i + 3] + udata[i + 4] * vdata[i + 4] + udata[i + 5] * vdata[i + 5]); for (; i &lt; length; i++) sum = sum + udata[i] * vdata[i]; *dest = sum; } /* CPE test */ #define N 1000000 #define LOOP 100 int main() { for (int num = 0; num &lt; 8; num++) { printf(&quot;---------#%d---------\\n&quot;, num + 1); vec_ptr u = new_vec(N + num); vec_ptr v = new_vec(N + num); data_t *udata = get_vec_start(u); data_t *vdata = get_vec_start(v); for (int i = 0; i &lt; N + num; i++) { udata[i] = (data_t)(rand() % 100); vdata[i] = (data_t)(rand() % 100); } clock_t start, end; data_t dest1, dest2, dest3, dest4; start = clock(); for (int i = 0; i &lt; LOOP; i++) inner4(u, v, &amp;dest1); end = clock(); printf(&quot;inner4: %8ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) inner_6_1(u, v, &amp;dest2); end = clock(); printf(&quot;inner_6_1: %8ld\\n&quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) inner_6_6(u, v, &amp;dest3); end = clock(); printf(&quot;inner_6_6: %8ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) inner_6_1a(u, v, &amp;dest4); end = clock(); printf(&quot;inner_6_1a: %8ld\\n&quot;, end - start); free(u); free(v); assert(dest1 == dest2); assert(dest1 == dest3); assert(dest1 == dest4); } } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 上进行测试，输出如下： ---------#1--------- inner4: 266654 | inner_6_1: 269248 inner_6_6: 130334 | inner_6_1a: 115673 ---------#2--------- inner4: 272794 | inner_6_1: 267059 inner_6_6: 133137 | inner_6_1a: 114011 ---------#3--------- inner4: 266166 | inner_6_1: 247058 inner_6_6: 133366 | inner_6_1a: 113238 ---------#4--------- inner4: 249148 | inner_6_1: 244997 inner_6_6: 132781 | inner_6_1a: 115536 ---------#5--------- inner4: 262702 | inner_6_1: 264659 inner_6_6: 135644 | inner_6_1a: 117583 ---------#6--------- inner4: 255991 | inner_6_1: 269604 inner_6_6: 132956 | inner_6_1a: 110715 ---------#7--------- inner4: 254987 | inner_6_1: 258611 inner_6_6: 130950 | inner_6_1a: 112928 ---------#8--------- inner4: 257418 | inner_6_1: 247065 inner_6_6: 130331 | inner_6_1a: 107883 5.16 见 5.15 5.17 #include &lt;assert.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;time.h&gt; void *basic_memset(void *s, int c, size_t n) { size_t cnt = 0; unsigned char *schar = (unsigned char *)s; while (cnt &lt; n) { *schar++ = (unsigned char)c; cnt++; } return s; } void *batch_memset(void *s, int c, size_t n) { size_t K = sizeof(unsigned long); unsigned char *schar = (unsigned char *)s; while ((unsigned long)schar % K != 0 &amp;&amp; n &gt; 0) { *schar++ = (unsigned char)c; n--; } unsigned long num = c &amp; 0xff; for (size_t i = 1; i &lt; K; i++) num |= num &lt;&lt; 8; unsigned long *slong = (unsigned long *)schar; while (n &gt;= K) { *slong++ = num; n -= K; } schar = (unsigned char *)slong; while (n &gt; 0) { *schar++ = (unsigned char)c; n--; } return s; } #define N 10000000 #define LOOP 100 int main() { size_t space = N; time_t start, end; void *basic_space = malloc(space); void *batch_space = malloc(space); size_t K = sizeof(unsigned long); for (size_t i = 0; i &lt; K; i++) { start = clock(); for (int i = 0; i &lt; LOOP; i++) basic_memset(((unsigned char *)basic_space + i), 0xaa - i, space - i); end = clock(); printf(&quot;basic malloc time: %ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) batch_memset(((unsigned char *)batch_space + i), 0xaa - i, space - i); end = clock(); printf(&quot;batch malloc time: %ld\\n&quot;, end - start); assert(memcmp(basic_space, batch_space, space) == 0); } free(basic_space); free(batch_space); } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 上进行测试，输出如下： basic malloc time: 887491 | batch malloc time: 146131 basic malloc time: 856498 | batch malloc time: 142887 basic malloc time: 870289 | batch malloc time: 149532 basic malloc time: 849905 | batch malloc time: 141645 basic malloc time: 872003 | batch malloc time: 141303 basic malloc time: 890140 | batch malloc time: 136793 basic malloc time: 869906 | batch malloc time: 139895 basic malloc time: 881630 | batch malloc time: 131402 5.18 #include &lt;assert.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; // Apply 6x3a loop unrolling double poly_6_3a(double a[], double x, long degree) { double acc0 = 0, acc1 = 0, acc2 = 0; double x2 = x * x; double x3 = x2 * x; double x4 = x2 * x2; double x5 = x3 * x2; double xpwr = 1; long i, limit = degree - 6; for (i = 0; i &lt;= limit; i += 6) { acc0 = acc0 + (a[i] + a[i + 1] * x) * xpwr; acc1 = acc1 + (a[i + 2] * x2 + a[i + 3] * x3) * xpwr; acc2 = acc2 + (a[i + 4] * x4 + a[i + 5] * x5) * xpwr; xpwr *= x3 * x3; } for (; i &lt;= degree; i++) { acc0 = acc0 + a[i] * xpwr; xpwr *= x; } return acc0 + acc1 + acc2; } // Apply 9x3a loop unrolling double poly_9_3a(double a[], double x, long degree) { double acc0 = 0, acc1 = 0, acc2 = 0; double x2 = x * x; double x3 = x2 * x; double x4 = x2 * x2; double x5 = x3 * x2; double x6 = x3 * x3; double x7 = x4 * x3; double x8 = x4 * x4; double xpwr = 1; long i, limit = degree - 9; for (i = 0; i &lt;= limit; i += 9) { acc0 = acc0 + (a[i] + a[i + 1] * x + a[i + 2] * x2) * xpwr; acc1 = acc1 + (a[i + 3] * x3 + a[i + 4] * x4 + a[i + 5] * x5) * xpwr; acc2 = acc2 + (a[i + 6] * x6 + a[i + 7] * x7+ a[i + 8] * x8) * xpwr; xpwr *= x6 * x3; } for (; i &lt;= degree; i++) { acc0 = acc0 + a[i] * xpwr; xpwr *= x; } return acc0 + acc1 + acc2; } double poly(double a[], double x, long degree) { long i; double result = a[0]; double xpwr = x; for (i = 1; i &lt;= degree; i++) { result += a[i] * xpwr; xpwr = x * xpwr; } return result; } /* apply horner's method */ double polyh(double a[], double x, long degree) { long i; double result = a[degree]; for (i = degree - 1; i &gt;= 0; i--) result = a[i] + x * result; return result; } #define N 10000000 #define LOOP 10 int main() { double x = 1.0; for (int num = 0; num &lt;= 8; num++) { long degree = N + num; double *a = (double *)malloc((degree + 1) * sizeof(double)); for (int i = 0; i &lt; degree; i++) a[i] = rand() % 100; printf(&quot;---------degree = %ld---------\\n&quot;, degree); double result1, result2, result3, result4; clock_t start, end; start = clock(); for(int i = 0; i &lt; LOOP; i++) result1 = poly_6_3a(a, x, degree); end = clock(); printf(&quot;poly_6_3a time spent: %8ld | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) result2 = poly(a, x, degree); end = clock(); printf(&quot;poly time spent: %8ld\\n&quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) result3 = poly_9_3a(a, x, degree); end = clock(); printf(&quot;poly_9_3a time spent: %8ld | &quot;, end - start); start = clock(); for(int i = 0; i &lt; LOOP; i++) result4 = polyh(a, x, degree); end = clock(); printf(&quot;polyh time spent: %8ld\\n&quot;, end - start); free(a); assert(result1 == result2); assert(result1 == result4); assert(result3 == result2); assert(result3 == result4); } } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 上进行测试，输出如下： ---------degree = 10000000--------- poly_6_3a time spent: 111917 | poly time spent: 264485 poly_9_3a time spent: 98027 | polyh time spent: 373688 ---------degree = 10000001--------- poly_6_3a time spent: 110967 | poly time spent: 265364 poly_9_3a time spent: 98061 | polyh time spent: 355811 ---------degree = 10000002--------- poly_6_3a time spent: 110771 | poly time spent: 254228 poly_9_3a time spent: 97843 | polyh time spent: 350948 ---------degree = 10000003--------- poly_6_3a time spent: 118869 | poly time spent: 257068 poly_9_3a time spent: 96964 | polyh time spent: 346912 ---------degree = 10000004--------- poly_6_3a time spent: 110924 | poly time spent: 247157 poly_9_3a time spent: 100290 | polyh time spent: 356883 ---------degree = 10000005--------- poly_6_3a time spent: 110079 | poly time spent: 247215 poly_9_3a time spent: 99898 | polyh time spent: 348652 ---------degree = 10000006--------- poly_6_3a time spent: 107007 | poly time spent: 248584 poly_9_3a time spent: 98824 | polyh time spent: 348210 ---------degree = 10000007--------- poly_6_3a time spent: 111019 | poly time spent: 242090 poly_9_3a time spent: 99284 | polyh time spent: 344494 ---------degree = 10000008--------- poly_6_3a time spent: 111483 | poly time spent: 246883 poly_9_3a time spent: 99805 | polyh time spent: 338931 5.19 #include &lt;assert.h&gt; #include &lt;memory.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; void psum_4_1a(double a[], double p[], long n) { long i; double last = 0.0; for (i = 0; i &lt;= n - 4; i += 4) { double tmp; p[i] = last + a[i]; tmp = last + (a[i] + a[i + 1]); p[i + 1] = tmp; p[i + 2] = tmp + a[i + 2]; last = tmp + (a[i + 2] + a[i + 3]); p[i + 3] = last; } for (; i &lt; n; i++) { last = last + a[i]; p[i] = last; } } void psum2a(double a[], double p[], long n) { long i; double last = 0.0; for (i = 0; i &lt;= n - 2; i += 2) { p[i] = last + a[i]; last = last + (a[i] + a[i + 1]); p[i + 1] = last; } for (; i &lt; n; i++) { last = last + a[i]; p[i] = last; } } void psum1a(double a[], double p[], long n) { long i; double last_val; last_val = p[0] = a[0]; for (i = 1; i &lt; n; i++) { last_val = last_val + a[i]; p[i] = last_val; } } #define N 10000000 #define LOOP 10 int main() { for (int num = 0; num &lt;= 8; num++) { double *a = (double *)malloc((N + num) * sizeof(double)); double *p1 = (double *)malloc((N + num) * sizeof(double)); double *p2 = (double *)malloc((N + num) * sizeof(double)); double *p3 = (double *)malloc((N + num) * sizeof(double)); for (int i = 0; i &lt; N + num; i++) a[i] = rand() % 100; clock_t start, end; start = clock(); for (int i = 0; i &lt; LOOP; i++) psum_4_1a(a, p1, N + num); end = clock(); printf(&quot;psum_4_1a time spent: %8ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) psum2a(a, p2, N + num); end = clock(); printf(&quot;psum2a time spent: %8ld | &quot;, end - start); start = clock(); for (int i = 0; i &lt; LOOP; i++) psum1a(a, p3, N + num); end = clock(); printf(&quot;psum1a time spent: %8ld\\n&quot;, end - start); int res1 = memcmp(p1, p3, (N + num) * sizeof(double)); int res2 = memcmp(p2, p3, (N + num) * sizeof(double)); free(a); free(p1); free(p2); free(p3); assert(res1 == 0); // memcmp(p1, p3, (N+num) * sizeof(double)) assert(res2 == 0); // memcmp(p2, p3, (N+num) * sizeof(double)) } } 在 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz 上进行测试，输出如下： psum_4_1a time spent: 223439 | psum2a time spent: 246537 | psum1a time spent: 340067 psum_4_1a time spent: 172092 | psum2a time spent: 198440 | psum1a time spent: 294900 psum_4_1a time spent: 179659 | psum2a time spent: 190736 | psum1a time spent: 281136 psum_4_1a time spent: 185108 | psum2a time spent: 184239 | psum1a time spent: 295593 psum_4_1a time spent: 171593 | psum2a time spent: 187729 | psum1a time spent: 292309 psum_4_1a time spent: 158491 | psum2a time spent: 202586 | psum1a time spent: 278818 psum_4_1a time spent: 187312 | psum2a time spent: 204946 | psum1a time spent: 282632 psum_4_1a time spent: 192022 | psum2a time spent: 214267 | psum1a time spent: 309177 psum_4_1a time spent: 191109 | psum2a time spent: 203226 | psum1a time spent: 281465 ","link":"https://SylvanasQAQ.github.io/post/gUdBg3EiE/"},{"title":"第 5 章 优化程序性能","content":"编写高效程序需要做到以下几点： 必须选择一组适当的算法和数据结构 必须编写出编译器能够有效优化以转换成高效可执行代码的源代码 对于第二点，理解优化编译器的能力和局限性是很重要的，编写程序方式的小变动可能会引起编译器优化方式很大的改变。现代编译器采用了复杂的分析和优化形式，但仍受到妨碍优化的因素 (optimization blocker) 的阻碍，这些因素是程序行为中那些严重依赖于执行环境的方面。 消除不必要的工作，让代码尽可能有效地执行所期望的任务：这包括消除不必要的函数调用、条件测试和内存引用，这些优化不依赖于目标机器的任何具体属性。 利用处理器提供的指令级并行 (instruction-level parallelism) 能力，同时执行多条指令。这些优化需要一个目标机器的模型，指明如何处理指令以及各个操作的时序特性。 5.1 优化编译器的能力和局限 大多数编译器 (如 GCC)，向用户提供了一些对它们所使用的优化的控制，最简单的控制就是指定优化级别： 命令行选项 &quot;-Og&quot; 可以让 GCC 使用一组基本的优化 命令行选项 &quot;-O1&quot; 或更高 (&quot;-O2&quot; 或 &quot;-O3&quot;) 调用 GCC 会让它使用更大量的优化 ⚠️高级别的优化可以进一步提高程序的性能，但是也可能增加程序的规模 (目标文件大小)，也可能使标准的调试工具更难对程序进行调试。 编译器对程序只使用安全的优化，即对于程序可能遇到的所有可能的情况，都保证优化后的程序和未优化的版本有一样的行为。看下面的一个例子： void twiddle1(long *xp, long *yp){ // read *xp twice, read *yp twice, write *xp twice *xp += *yp; *xp += *yp; } void twiddle2(long *xp, long *yp){ // read *xp once, read *yp once, write *xp once *xp += 2* *yp; } 这两个过程似乎有相同的行为，其中函数 twiddle2 效率更高一点，只需要 3 次内存引用，而 twiddle1 需要 6 次。但是考虑 xp 等于 yp 的情况，两个函数的结果并不相同，因此编译器不会产生 twiddle2 风格的代码作为 twiddle1 的优化版本。 两个指针可能指向同一个内存位置的情况称为内存别名使用 (memory aliasing)，这是一个主要的妨碍优化的因素。如果编译器不能确定两个指针是否指向同一个位置，就必须假设什么情况都有可能，这就限制了可能的优化策略。 编译器的安全优化行为还有一个例子——程序的副作用，考虑下面两个过程： long f; long func1() { return f() + f() + f() + f(); } long func2() { return 4*f(); } func2 看似可以作为 func1 的优化版本，但考虑下面 f 的代码： long counter = 0; long f() { return counter++; } 这个函数有个副作用——它修改了全局程序状态的一部分，改变调用它的次数会改变程序的行为。大多数编译器不会试图判断一个函数是否没有副作用，相反编译器会假设最糟的情况，并保持所有的函数调用不变。 5.2 表示程序性能 引入表示程序性能并指导我们改进代码的度量标准：每元素的周期数 (Cycle Per Element, CPE)。CPE 可以帮助我们在更细节的级别上理解迭代程序的循环性能。 下面展示一个例子来帮助理解 CPE，函数 psum1 和 psum2 计算一个长度为 nnn 的向量的前缀和 (prefix sum)。对于一个向量 a⃗=⟨a0,a1,⋯ ,an−1⟩\\vec{a}=\\left\\langle a_{0}, a_{1}, \\cdots, a_{n-1}\\right\\ranglea=⟨a0​,a1​,⋯,an−1​⟩，前缀和 p⃗=⟨p0,p1,⋯ ,pn−1⟩\\vec{p}=\\left\\langle p_{0}, p_{1}, \\cdots, p_{n-1}\\right\\ranglep​=⟨p0​,p1​,⋯,pn−1​⟩ 定义为 p0=a0pi=pi−1+ai,1⩽i&lt;n\\begin{aligned} p_{0} &amp;=a_{0} \\\\ p_{i} &amp;=p_{i-1}+a_{i}, \\quad 1 \\leqslant i&lt;n \\end{aligned} p0​pi​​=a0​=pi−1​+ai​,1⩽i&lt;n​ void psum1(float a[], float p[], long n){ long i; p[0] = a[0]; for (i = 1; i &lt; n; i++) p[i] = p[i-1] + a[i]; } void psum2(float a[], float p[], long n){ long i; p[0] = a[0]; for (i = 1; i &lt; n-1; i++){ float mid_val = p[i-1] + a[i]; p[i] = mid_val; p[i+1] = mid_val + a[i+1]; } if (i &lt; n) p[i] = p[i-1] + a[i]; } 函数 psum1 每次迭代计算结果向量的一个元素，函数 psum2 使用循环展开 (loop unrolling) 技术每次迭代计算两个元素。这样一个过程所需要的时间可以用一个常数加上一个与被处理元素个数成正比的因子来描述，下图是这两个函数需要的周期数关于 nnn 的取值范围图。对于较大的 nnn 值，运行时间就会主要由线性因子来决定，根据下图可以得到 psum2 的 CPE 为 6.06.06.0，优于 CPE 为 9.09.09.0 的 psum1。 5.3 程序示例 为了说明程序是如何被系统地转换成更有效的代码的，使用一个基于向量数据结构的运行示例进行展示。向量数据结构由两个内存块表示：头部和数据数组。 头部的声明如下： typedef struct { long len; data_t *data; } vec_rec, *vec_ptr; 用 data_t 表示基本元素的数据类型，在测试中为度量代码对于整数和浮点数数据的性能，会分别为不同的类型声明编译和运行程序，对数据类型 long 进行测试只需 typedef long data_t; 下面是一些生成向量、访问向量元素以及确定向量长度的基本过程： vec_ptr new_vec(long len){ // Allocate header structure vec_ptr pHeader = (vec_ptr) malloc(sizeof(vec_rec)); data_t *pData = NULL; if (!pHeader) return NULL; // Couldn't allocate storage pHeader-&gt;len = len; // Allocate array if (len &gt; 0){ pData = (data_t *) calloc(len, sizeof(data_t)); if (!pData){ free((void *) pHeader); return NULL; // Couldn't allocate storage } } // Data will either be NULL or allocated array pHeader-&gt;data = pData; return pHeader; } int get_vec_element(vec_ptr v, long index, data_t *dest){ if (index &lt; 0 || index &gt;= v-&gt;len) return 0; // Out of bounds *dest = v-&gt;data[index]; return 1; // Success } long vec_length(vec_ptr v){ return v-&gt;len; } 在了解过向量的数据结构后，再考虑下面基于向量的运行示例代码，它使用某种运算，将一个向量中所有的元素合并成一个值。通过使用宏定义 IDENTITY 和 OP 的不同定义，这段代码可以重编译成对数据执行不同的运算。 // 对向量元素求和 #define IDENTITY 0 #define OP + // 计算向量元素的乘积 #define IDENTITY 1 #define OP * void combine1(vec_ptr v, data_t *dest){ long i; *dest = IDENTITY; for (i = 0; i &lt; vec_length(v); i++) { data_t val; get_vec_element(v, i, &amp;val); *dest = *dest OP val; } } 接下来我们将对这段代码进行一系列的变化，写出这个合并函数的不同版本，在 Intel Core i7 Haswell 处理器 (参考机) 上测量这些函数的 CPE 性能。我们会尝试不同的变换，其中有很多只能带来很小的性能提升，而有些则能带来巨大的效果。最好的方法是实验加上分析：反复地尝试不同的方法，进行测量，并检查汇编代码表示以确定底层的性能瓶颈。 下表是 combine1 的 CPE 度量值 (经过测试，323232 位整数操作和 646464 位整数操作有相同的性能，单精度和双精度浮点数据的性能也相同，所以在表中只给出整数数据和浮点数据各自的结果)。 未经优化的代码是从 C 语言代码到机器代码的直接翻译，通常效率明显较低，养成至少使用 -O1 级别优化的习惯是很好的。 5.4 消除循环的低效率 combine2 在开始时调用 vec_length，并将结果赋给局部变量 length。对于某些数据类型和操作的组合，这个变换明显地影响了整体性能，对于其他的则只有很小甚至没有影响。 void combine2(vec_ptr v, data_t•dest){ long i; long length = vec_length(v); *dest = IDENTITY; for (i = 0; i &lt; length; i++) { data_t val; get_vec_element(v, i, &amp;val); *dest = *dest OP val; } } 这种优化被称为代码移动：识别要执行多次但是计算结果不会改变的计算，然后将计算移动到代码前面不会被多次求值的部分。优化编译器会试着进行代码移动，但对于会改变在哪里调用函数或调用多少次的变换，编译器通常会非常小心。它们不能可靠地发现一个函数是否会有副作用，因而假设函数会有副作用。 5.5 减少过程调用 过程调用会带来开销，而且妨碍大多数形式的程序优化。在 combine2 的代码中可以看出，每次循环迭代都会调用 get_vec_element 来获取下一个向量元素。而每次调用这个函数时，它都要把向量索引 iii 与循环边界做比较，很明显会造成低效率。在处理任意的数组访问时，边界检查可能是个很有用的特性，而且 combine2 的代码中所有引用都是合法的。 假设向量的抽象数据类型增加一个函数 get_vec_start，它返回数组的起始地址，借助这个函数我们可以得到过程 combine3。它没有用函数调用来获取每个向量元素，而是直接访问数组。虽然这种变换严重损害了程序的模块性，但如果可以获得性能的大幅提升也可以接受😏。 data_t *get_vec_start(vec_ptr v){ return v-&gt;data; } void combine3(vec_ptr v, data_t *dest){ long i; long length = vec_length(v); data_t * data = get_vec_start(v); *dest = IDENTITY; for (i = 0; i &lt; length; i++) { *dest = *dest OP data[i]; } } 令人吃惊的是，性能没有明显的提升，整数求和的性能反而还略有下降😱。显然内循环中的其他操作形成了瓶颈，限制性能超过调用 get_vec_element，后面会解释为什么 combine2 中反复的边界检查不会让性能更差 (分支预测)。 5.6 消除不必要的内存引用 combine3 将合并运算计算的值累积在指针 dest 指定的位置，通过检查编译出来的为内循环产生的汇编代码，可以看出这个属性。可以看到每次迭代时，累积变量的数值都要从内存读出再写入到内存。这样的读写很浪费，因为每次迭代开始时从 dest 读出的值就是上次迭代最后写入的值。 ; Inner loop of combine3, data_t = double, OP = * ; dest in %rbx, data+i in %rdx, data+length in %rax .L17: vmovsd (%rbx), %xmm0 ; Read product from dest vmulsd (%rdx), %xmm0, %xmm0 vmovsd %xmm0, (%rbx) ; Store product at dest addq $8, %rdx cmpq %rax, %rdx jne .L17 为了消除这种不必要的内存读写，引入一个临时变量 acc，它在循环中用来累积计算出来的值，只有在循环完成之后结果才存放在 dest 中。 void combine4(vec_ptr v, data_t•dest){ long i; long length = vec_length(v); data_t * data = get_vec_start(v); data_t acc = IDENTITY; for (i = 0; i &lt; length; i++) acc = acc OP data[i]; *dest = acc; } 检查汇编代码可以看到，编译器现在可以用寄存器 %xmm0 来保存累积值。与 combine3 中的循环相比，将每次迭代的内存操作从两次读和一次写减少到只需要一次读。 .L25: vmulsd (%rdx), %xmm0, %xmm0 ; Multiply acc by data[i] addq $8, %rdx cmpq %rax, %rdx jne .L17 可以看到程序性能有了显著的提高，如下表所示： 既然 combine4 的提升这么大，编译器能自动将 combine3 的代码转换过去吗？很不幸，由于内存别名使用，两个函数可能会有不同的行为，因此编译器会选择保守地不断读和写内存。考虑下面这种情况： // data_t = long, OP = * // v = [2, 3, 5] combine3(v, get_vec_start(v) + 2); // res = [2, 3, 36] combine4(v, get_vec_start(v) + 2); // res = [2, 3, 30] 当用带命令行选项 -O2 的 GCC 来编译 combine3 时，得到的代码 CPE 性能远好于使用 -O1 的： 在检查编译器产生的汇编代码时，可以发现对内循环的一个有趣变化： ; Inner loop of combine3, data_t = double, OP = *. Compiled -O2 ; dest in %rbx, data+i in %rdx, data+length in %rax .L22: vmulsd (%rdx), %xmm0, %xmm0 addq $8, %rdx cmpq %rax, %rdx vmovsd %xmm0, (%rbx) ; Store product at dest jne .L22 除了指令顺序有些不同，-O2 与 -O1 优化等级的唯一的区别就是使用更优化的版本不含有 vmovsd 指令，它实现的是从 dest 指定的位置读数据。接下来我们想看看是什么因素在制约着代码的性能，以及为什么减少一条指令可以大幅降低 CPE (写/读相关)。 5.7 理解现代处理器 到目前为止，所有介绍的优化手段都不依赖于目标机器的任何特性，这些优化只是简单地降低了过程调用的开销，以及消除一些重大的“妨碍优化的因素”。要想进一步提高性能，必须考虑利用处理器微体系结构的优化，也就是处理器用来执行指令的底层系统设计。 两种下界描述了程序的最大性能：当一系列操作必须按照严格顺序执行时，就会遇到延迟界限 (latency bound)；吞吐量界限 (throughput bound) 刻画了处理器功能单元的原始计算能力。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。 5.7.1 整体操作 现代微处理器的特点： 指令级并行：同时对多条指令求值 超标量 (superscalar)：可以在每个时钟周期执行多个操作 乱序 (out-of-order)：指令执行的顺序不 一定要与它们在机器级程序中的顺序一致 现代微处理器的设计有两个主要部分： 指令控制单元 (Instruction Control Unit, ICU)，从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作 (微操作) 执行单元 (Execution Unit, EU)，执行上述生成的基本操作 ICU 的取指控制逻辑从指令高速缓存 (instruction cache) 中读取指令，指令高速缓存含最近访问的指令。 分支预测 (branch prediction) 技术：处理器会猜测是否会选择分支，同时还预测分支的目标地址 投机执行 (speculative execution) 技术：处理器会开始取出位于它预测的分支会跳到的地方的指令，并对指令译码，甚至在它确定分支预测是否正确之前就开始执行这些操作 ❌如果过后确定分支预测错误，会将状态重新设置到分支点的状态，并开始取出和执行另一个方向上的指令 退役单元 (retirement unit) 记录正在进行的处理，用于防止分支预测错误 ICU 的指令译码逻辑接收实际的程序指令，并将它们转换成一组基本操作 (微操作)。每个微操作都完成某个简单的计算任务：例如两个数相加，从内存中读数据，或是向内存写数据。 EU 接收来自取指单元的操作，每个时钟周期会接收多个操作。这些操作会被分派到一组功能单元中，它们会执行实际的操作。Intel Core i7 Haswell 参考机有 888 个功能单元： 执行单元可以直接将结果发送给彼此，控制操作数在执行单元间传送的最常见的机制称为寄存器重命名 (register renaming)。通过这种机制，值可以从一个操作直接转发到另一个操作，而不是写到寄存器文件再读出来，使得第二个操作能够在第一个操作完成后尽快开始。 5.7.2 功能单元的性能 Intel Core i7 Haswell 参考机算术运算的性能可以由以下几个指标衡量： 延迟 (latency)：完成运算所需要的总时间 发射时间 (issue time)：两个连续的同类型的运算之间需要的最小时钟周期数 容量 (capacity)：能够执行该运算的功能单元的数量 从上表可以看出，加法和乘法运算的发射时间都为 111，即在每个时钟周期处理器都可以开始一条新的这样的运算。这种很短的发射时间是通过流水线实现的，发射时间为 111 的功能单元被称为完全流水线化的 (fully pipelined)。容量大于 111 的运算是由于有多个功能单元。除法器不是完全流水线化的，其延迟和发射时间是以范围的形式给出的，长延迟和长发射时间使得除法成为了一个相对开销很大的运算。 最大吞吐量定义为发射时间的倒数，具有多个功能单元可以进一步提高吞吐量。对一个容量为 CCC，发射时间为 III 的操作来说，处理器可能获得的吞吐量为每时钟周期 C/IC/IC/I 个操作，比如 Haswell 参考机可以每个时钟周期执行两个浮点乘法运算。为什么是可能呢？因为需要从内存读数据，这造成了另一个吞吐量界限。两个加载单元限制了处理器每个时钟周期最多只能读取两个数据值，从而使得吞吐量界限为 0.500.500.50 (CPE 值)。 5.7.3 处理器操作的抽象模型 程序的数据流 (data-flow) 表示是一种图形化的表示方法，可用于分析机器级程序性能，展示了不同操作之间的数据相关是如何限制它们的执行顺序的，这些限制形成了图中的关键路径 (critical path)，这是执行一组机器指令所需时钟周期数的一个下界。 以 combine4 为例描述数据流表示法，将注意力集中在循环执行的计算上，汇编代码如下： ; Inner loop of combine4. data_t = double, OP = * .L25: vmulsd (%rdx), %xmm0, %xmm0 ; Multiply acc by data[i] addq $8, %rdx cmpq %rax, %rdx jne .L17 指令译码器会把这 4 条指令扩展成五步操作，最开始的乘法指令被扩展成一个 load 操作 (从内存读出源操作数) 和一个 mul 操作。下图中的顶部方框表示循环开始时寄存器的值，底部方框表示最后寄存器的值。某些操作产生的值不对应于任何寄存器，用操作间的弧线表示。 对于形成循环的代码片段，可以将访问到的寄存器分为四类： 只读：只用作源值，在循环中不会被修改 只写：作为数据传送操作的目的 局部：在循环内部被修改和使用，迭代与迭代之间不相关，比如条件码寄存器 (cmp 操作修改，jne 操作使用) 循环：既作为源值，又作为目的，一次迭代中产生的值会在另一次迭代中用到 (⚠️循环寄存器之间的操作链决定了限制性能的数据相关) 下图 a) 删去了局部寄存器，并将不属于循环寄存器相关链的操作符标识为白色。下图 b) 继续进行简化，只保留了循环寄存器和与其相关的操作符，该图表明的是由于循环的一次迭代在循环寄存器中形成的数据相关。 下图是将上面的 b) 图重复 nnn 次得到的 combine4 内循环 nnn 次迭代的数据流表示，可以看到程序有两条数据相关链。由于浮点乘法延迟大于整数加法延迟，所以左边的链会成为关键路径，需要 5n5n5n 个周期执行。 延迟界限是基本的限制，下面我们重新调整操作的结构，增强指令级并行性，使得 CPE 逼近吞吐量界限✈️。 5.8 循环展开 循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。循环展开能够从两个方面改进程序的性能： 减少了不直接有助于程序结果的操作数量，如循环索引计算和条件分支 提供了可进一步变换代码的方法，减少整个计算中关键路径上的操作数量 k×1k \\times 1k×1 循环展开：循环展开因子为 kkk，累积因子只在单个变量 acc 中。combine5 使用了 2×12 \\times 12×1 循环展开减小循环开销的影响： void combine5(vec_ptr v, data_t *dest){ long i; long length = vec_length(v); long limit = length-1; // Jump over the first loop when length &lt; 2 data_t *data = get_vec_start(v); data_t acc = IDENTITY; for (i = 0; i &lt; limit; i+=2) acc = (acc OP data[i]) OP data[i+1]; for (; i &lt; length; i++) acc = acc OP data[i]; *dest = acc; } 在上表中可以看到对于整数加法，CPE 有所改进，得到的延迟界限为 1.001.001.00；但其他情况并没有性能提高。要理解为什么 k×1k \\times 1k×1 循环展开不能将性能改进到超过延迟界限，需要查看 combine5 的内循环的机器级代码： .L35: vmulsd (%rax, %rdx, 8), %xmm0, %xmm0 vmulsd 8(%rax, %rdx, 8), %xmm0, %xmm0 addq $2, %rdx cmpq %rdx, %rbp jg .L35 从下面的数据流表示可以看出，图中关键路径还是 nnn 个 mul 操作——迭代次数减半了，但是每次迭代中还是有两个顺序的乘法操作。这个关键路径是循环没有展开代码的性能制约因素，也是 k×1k \\times 1k×1 循环展开代码的性能制约因素。 💡编译器可以很容易地执行循环展开，用优化等级 333 或更高等级调用 GCC，它就会执行循环展开 5.9 提高并行性 程序的性能是受运算单元的延迟限制的，执行加法和乘法的功能单元可以每个时钟周期开始一个新操作，并且这些操作可以被多个功能单元执行。虽然硬件具有以更高速率执行乘法和加法的潜力，但是之前的代码都不能利用这种能力，因为累积值被放在了一个单独的变量 acc 中，在前面的计算完成之前，都不能计算 acc 的新值。现在要考察打破这种顺序相关，得到比延迟界限更好性能的方法。 5.9.1 多个累积变量 对于一个可结合和可交换的合并运算来说 (整数加法或乘法)，可以通过将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能。combine6 使用了两次循环展开，以使每次迭代合并更多的元素，索引值为为偶数的元素累积在 acc0 中，索引值为奇数的元素累积在 acc1 中，因此被称为 2×22 \\times 22×2 循环展开。 void combine6(vec_ptr v, data_t *dest){ long i; long length = vec_length(v); long limit = length-1; data_t *data = get_vec_start(v); data_t acc0 = IDENTITY; data_t acc1 = IDENTITY; for (i = 0; i &lt; limit; i+=2) { acc0 = acc0 OP data[i]; acc1 = acc1 OP data[i+1]; } for (; i &lt; length; i++) acc0 = acc0 OP data[i]; *dest = acc0 OP acc1; } 比较只做循环展开和既做循环展开同时也使用两路并行这两种方法，可以得到下面的性能： 可以看到所有情况都得到了改进，整数乘、浮点加、浮点乘改进了约 222 倍，整数加法也有所改进。更棒的是 combine6 打破了由延迟界限设下的限制，处理器不再需要等待前一个运算操作的完成。在下面的数据流图中有两条关键路径，每条关键路径只包含 n/2n/2n/2 个操作，因此 CPE 大约为延迟界限的一半。 只有保持能够执行该操作的所有功能单元的流水线都是满的，程序才能达到这个操作的吞吐量界限。对延迟为 LLL，容量为 CCC 的操作而言，要求循环展开因子 k≥C⋅Lk \\ge C \\cdot Lk≥C⋅L。 在执行 k×kk \\times kk×k 循环展开变换时，必须考虑是否要保留原始函数的功能。补码运算是可交换和可结合的，甚至是当溢出时也是如此。因此对于整数数据类型，combine6 的结果与 combine5 相同，优化编译器能够进行类似的变换来提高整数数据的性能。⚠️浮点乘法和加法不是可结合的，由于四舍五入或溢出，combine5 和 combine6 可能产生不同的结果。因此大多数编译器并不会尝试对浮点数代码进行这种变换，因为它们没有办法判断引入这种会改变程序行为的转换所带来的风险。在面临这种情况时，程序开发人员应该与潜在的用户协商，看是否有特殊的条件可能会导致修改后的算法不能接受，毕竟对于大多数应用程序来说，使性能翻倍要比冒对奇怪的数据模式产生不同的结果的风险更重要。 5.9.2 重新结合变换 做 k×1k \\times 1k×1 循环展开的 combine5 没有改变合并向量元素形成和或者乘积中执行的操作，但只需要对代码做很小的改动，我们就可以从根本上改变合并执行的方式，同时极大地提高程序的性能。 // Conbination operation in combine5 acc = (acc OP data[i]) OP data[i+1]; // Conbination operation in combine7 acc = acc OP (data[i] OP data[i+1]); 差别仅在于两个括号是如何放置的，称这种变换为重新结合变换 (reassociation transformation)，因为括号改变了向量元素与累积值 acc 的合并顺序，产生了 2×1a2 \\times 1a2×1a 循环展开形式。这种变换虽然微乎其微，但 CPE 性能却好得出乎意料，突破了延迟界限造成的限制： .L39: vmovsd (%rax, %rdx, 8), %xmm0 vmulsd 8(%rax, %rdx, 8), %xmm0, %xmm0 vmulsd %xmm0, %xmm1, %xmm1 addq $2, %rdx cmpq %rdx, %rbp jg .L39 来自 vmovsd 和第一个 vmulsd 指令的 load 操作从内存中加载向量元素 iii 和 i+1i+1i+1，第一个 mul 操作把它们乘起来，第二个 mul 操作把这个结果乘以累积值 acc。虽然有两个 load 和两个 mul 操作，但是只有一个 mul 操作形成了循环寄存器间的数据相关链，每次迭代内的第一个乘法都不需要等待前一次迭代的累积值就可以执行。 ⚠️重新结合变换也改变了向量元素合并的顺序，对于整数加法和乘法这些可结合运算，重新变换顺序对结果没有影响。对于浮点数情况，必须再次评估这种重新结合是否有可能严重影响结果。对大多数应用来说，这种差别不重要。总的来说，重新结合变换能够减少计算中关键路径上操作的数量，通过更好地利用功能单元的流水线能力得到更好的性能。 5.11 一些限制因素 在一个程序的数据流图表示中可以看出，关键路径指明了执行该程序所需时间的一个基本下界。功能单元的吞吐量界限也是程序执行时间的一个下界，下面介绍其他一些制约程序在实际机器上性能的因素。 5.11.1 寄存器溢出 循环并行性的好处受汇编代码描述计算的能力限制，如果并行度 ppp 超过了可用的寄存器数量，编译器会诉诸溢出 (spilling)，将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。现代 x86-64 处理器有 16 个寄存器，可以使用 16 个 YMM 寄存器来保存浮点数。一旦循环变量的数量超过了可用寄存器的数量，程序就必须在栈上分配一些变量。 一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就很可能消失。不过 x86-64 有足够多的寄存器，大多数循环在出现寄存器溢出之前就将达到吞吐量限制。 5.11.2 分支预测和预测错误处罚 💡当分支预测逻辑不能正确预测一个分支是否要跳转的时候，条件分支可能会招致很大的预测错误处罚。使用投机执行的处理器会开始执行预测的分支目标处的指令，它会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。如果预测正确，那么处理器会将结果存储到寄存器或内存；如果预测错误，必须丢弃掉所有投机执行的结果。 现代的 x86 处理器有条件传送指令，在编译条件语句和表达式的时候，GCC 能产生使用条件传送指令的代码，而不是更传统的基于控制的条件转移的实现。条件传送指令可以被实现为普通指令流水线化处理的 一部分，没有必要猜测条件是否满足，因此猜测错误也没有处罚。 不要过分关心可预测的分支 错误的分支预测的影响可能非常大，但是这并不意味着所有的程序分支都会减缓程序的执行。在合并函数中结束循环的分支通常会被预测为选择分支，因此只在最后一次会导致预测错误处罚。 当从 combine2 变化到 combine3 时，把函数 get_vec_element 从内循环中拿了出来，但 CPE 基本上没变，即使这个转变消除了每次迭代中用于检查向量索引是否在界限内的两个条件语句。对这个函数来说，这些检测总是确定索引是在界内的，所以是高度可预测的✅。 书写适合用条件传送实现的代码 分支预测只对有规律的模式可行。程序中的许多测试是完全不可预测的，依赖于数据的任意特性，例如一个数是负数还是正数。对于这些测试，分支预测逻辑会处理得很糟糕。对于本质上无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大地提高程序的性能。这不是 C 语言程序员可以直接控制的，但是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。 功能性风格：用条件操作来计算值，然后用这些值来更新程序状态 命令式风格：用条件语句来有选择地更新程序状态 💡GCC 能够为功能性风格书写的代码产生条件传送 // 命令式风格，随机数据上的 CPE 性能为 13.50 // 可预测数据的 CPE 为 2.5~3.5，预测错误乘法为 20 个周期 void minmax1(long a[], long b [], long n) { long i; for (i = 0; i &lt; n; i++){ if (a[i] &gt; b[i]) { long t = a[i]; a[i] = b[i]; b[i] = t; } } // 功能性风格，随机数据上的 CPE 性能为 4.0 void minmax2(long a[], long b [], long n) { long i; for (i = 0; i &lt; n; i++){ long min = a[i] &lt; b[i] ? a[i] : b[i]; long max = a[i] &lt; b[i] ? b[i] : a[i]; a[i] = max; b[i] = min; } } 5.12 理解内存性能 现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的内存操作请求集合：Intel Core i7 Haswell 有两个加载单元，每一个可以保存多达 72 个未完成的读请求、最多 42 个写请求。 5.12.1 加载的性能 一个包含加载操作的程序的性能既依赖于流水线的能力，依赖于加载单元的延迟。对两个加载单元而言，其每个时钟周期只能启动一条加载操作，所以 CPE 不可能小于 0.50。要确定一台机器上加载操作的延迟，可以建立由一系列加载操作组成的一个计算，一条加载操作的结果决定下一条操作的地址。比如计算链表长度的函数 list_len，测试表明其 CPE 为 4.00，这直接表明了加载操作的延迟，该结果也与 L1 级 cache 的 4 周期访问时间是一致的。 5.12.2 存储的性能 与加载操作一样，在大多数情况中，存储操作能够在完全流水线化的模式中工作，每个周期开始一条新的存储。下面的函数将一个长度为 nnn 的数组 dest 的元素设置为 000，其 CPE 等于 1.00，对于只具有单个存储功能单元的机器，这巳经达到了最佳情况。 void clear_array(long *dest, long n) { long i; for (i = 0; i &lt; n; i++) dest[i] = 0; } 存储操作并不影响任何寄存器值，所以一系列存储操作不会产生数据相关，只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值。在下面的示例中，当 src 指向数组元素 a[0]，而 dest 指向数组元素 a[1] 时，从 src 读出的结果不受对 dest 的写的影响，这种情况下的 CPE 等于 1.3。如果 src 和 dest 都指向数组元素 a[0] 时，src 的每次加载都会得到指针引用 *dest 的前次执行存储的值，CPE 为 7.3。这种现象称为写/读相关 (write/read dependency)，写/读相关导致处理速度下降约 6 个时钟周期。 void write_read(long *src, long *dest, long n){ long cnt = n; long val = 0; while (cnt) { *dest = val; val = (*src) + 1; cnt--; } } 要了解这两种情况的性能差异为什么这么大，必须仔细地看看加载和存储执行单元。存储单元包含一个存储缓冲区，它包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没有地址相匹配。如果有地址相匹配，它就取出相应的数据条目作为加载操作的结果。 movq %rax, (%rsi) 被翻译为两个操作： s_addr：计算存储操作的地址，在存储缓冲区创建一个条目 s_data：计算该条目的数据字段 而 movq (%rdi), %rax 译码得到的 load 操作必须检查所有未完成的存储操作的地址，在这个操作和 s_addr 操作之间创建一个数据相关。s_data 和 load 操作之间的数据相关是有条件的：如果两个地址相同，load 操作必须等待直到 s_data 将它的结果存放到存储缓冲区中；如果两个地址不同，两个操作就可以独立地进行。 下图说明了 write_read 内循环操作之间的数据相关：弧线①表示存储地址必须在数据被存储之前计算出来，弧线②表示需要 load 操作将它的地址与所有未完成的存储操作的地址进行比较，虚线③表示条件数据相关， 当加载和存储地址相同时会出现。 当 src 和 dest 不同时，加载和存储操作可以独立进行，因此唯一的关键路径是由减少变量 cnt 形成的，此时 CPE 为 1.0。当 src 和 dest 相同时，s_data 和 load 指令之间的数据相关使得关键路径的形成包括了存储、加载和增加数据，此时 CPE 超过 7.0。 5.13 应用：性能提高技术 高级设计：选择适当的算法和数据结构 基本编码原则：消除连续的函数调用，消除不必要的内存引用 低级优化：循环展开，多个累积变量，重新结合技术，功能性风格重写条件操作 5.15 小结 没有任何编译器能用一个好的算法或数据结构代替低效率的算法或数据结构，因此程序设计的这些方面仍然应该是程序员主要关心的。妨碍优化的因素，如内存别名使用和过程调用，也会严重限制编译器执行大量优化的能力。这些应该被看作好的编程习惯的一部分，消除不必要的工作。 拥有一些对处理器微体系结构的理解，如操作、容量、延迟和功能单元发射时间的信息，就能够基本地预测程序的性能了。使用现代处理器提供的指令级并行技术：循环展开、创建多个累积变量和重新结合。确认由程序中的数据相关决定的关键路径，尤其是循环的不同迭代之间的数据相关，会收获良多。 包含条件分支或与内存系统复杂交互的程序，更难以分析和优化。基本策略是使分支更容易预测，或者使它们很容易用条件数据传送来实现。还必须注意存储和加载操作，将数值保存在局部变量中，使得它们可以存放在寄存器中。 ","link":"https://SylvanasQAQ.github.io/post/-Z1feBTkT/"}]}